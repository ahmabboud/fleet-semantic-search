{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a426990c",
   "metadata": {},
   "source": [
    "## ğŸ”§ Code Quality: Single Source of Truth\n",
    "\n",
    "This notebook follows the **Single Source of Truth** principle for all configuration values:\n",
    "\n",
    "### ğŸ“ **Configuration Variables** (Defined Once, Used Everywhere)\n",
    "\n",
    "- `COLLECTION_NAME = \"seatbelt_comments\"` - Vector database collection name\n",
    "- `PERSIST_DIRECTORY = os.path.join(os.getcwd(), \"chroma_db\")` - Database storage location  \n",
    "- `SIMILARITY_THRESHOLD = 0.7` - Default similarity threshold for searches\n",
    "- `embedding_model` - OpenAI embedding model from `.env` file\n",
    "- `llm_model` - LLM model for validation from `.env` file\n",
    "\n",
    "### âœ… **Benefits of This Approach**\n",
    "\n",
    "1. **Consistency**: All functions use the same configuration values\n",
    "2. **Maintainability**: Change values in one place to update everywhere\n",
    "3. **No Hardcoding**: Print statements and function calls reference variables\n",
    "4. **Flexibility**: Easy to modify thresholds and paths for different use cases\n",
    "\n",
    "### ğŸš« **What We Avoided**\n",
    "\n",
    "- âŒ Hardcoded `\"chroma_db\"` strings in print statements\n",
    "- âŒ Hardcoded `0.7`, `0.6`, `0.5` threshold values in functions\n",
    "- âŒ Hardcoded `\"seatbelt_comments\"` collection names\n",
    "- âŒ Duplicate configuration values scattered throughout code\n",
    "\n",
    "This ensures reliable, maintainable code that's easy to configure and modify.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8cb8c1",
   "metadata": {},
   "source": [
    "# Semantic Search Demo with Excel Data\n",
    "\n",
    "This notebook will:\n",
    "1. Read and understand the Excel file structure\n",
    "2. Prepare the data for semantic search\n",
    "3. Create a vector database\n",
    "4. Demonstrate semantic search capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5af8041f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Display pandas dataframes in a more readable format\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc36ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Lm_orders_seatbelt_v2.xlsx\n",
      "Number of rows: 237\n",
      "Number of columns: 11\n",
      "\n",
      "Column names:\n",
      "- orderid\n",
      "- Orderstatus\n",
      "- Completedate\n",
      "- Compcode\n",
      "- Compcodedescrip\n",
      "- Sectioncomments\n",
      "- Linetype\n",
      "- Hours\n",
      "- Qty\n",
      "- Unitcst\n",
      "- linetotal\n",
      "\n",
      "First 5 rows of data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "orderid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Orderstatus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Completedate",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Compcode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Compcodedescrip",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sectioncomments",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Linetype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Hours",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Qty",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unitcst",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "linetotal",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c7ec21c6-b49d-44d7-9dcc-4a6ca80c36c9",
       "rows": [
        [
         "0",
         "12383330",
         "REPAIR      ",
         "2025-03-05 16:23:00",
         "002-011-003 ",
         "Seat Belt & Retainer Assembly                               ",
         "<Complaint>Seatbelt</Complaint><Cause>Check van find driver seatbelt latch not working </Cause><Correction>Remove seat belt latch and replace with a new seat belt latch on van but itâ€™s still saying that the seatbelt is malfunctioning </Correction><Estimate></Estimate><Notes>This van need to go at the dealership so that all the module for the seatbelt drive side can be check </Notes>",
         "LABOR       ",
         "1.0",
         "0",
         "110.0",
         "110.0"
        ],
        [
         "1",
         "12383330",
         "REPAIR      ",
         "2025-03-05 16:23:00",
         "002-011-003 ",
         "Seat Belt & Retainer Assembly                               ",
         "<Complaint>Seatbelt</Complaint><Cause>Check van find driver seatbelt latch not working </Cause><Correction>Remove seat belt latch and replace with a new seat belt latch on van but itâ€™s still saying that the seatbelt is malfunctioning </Correction><Estimate></Estimate><Notes>This van need to go at the dealership so that all the module for the seatbelt drive side can be check </Notes>",
         "PART        ",
         "0.0",
         "1",
         "369.7",
         "369.7"
        ],
        [
         "2",
         "12383330",
         "REPAIR      ",
         "2025-03-05 16:23:00",
         "002-011-003 ",
         "Seat Belt & Retainer Assembly                               ",
         "<Complaint>Seatbelt</Complaint><Cause>Check van find driver seatbelt latch not working </Cause><Correction>Remove seat belt latch and replace with a new seat belt latch on van but itâ€™s still saying that the seatbelt is malfunctioning </Correction><Estimate></Estimate><Notes>This van need to go at the dealership so that all the module for the seatbelt drive side can be check </Notes>",
         "PART        ",
         "0.0",
         "1",
         "142.1",
         "142.1"
        ],
        [
         "3",
         "12482815",
         "REPAIR      ",
         "2025-03-05 04:17:00",
         "002-011-003 ",
         "Seat Belt & Retainer Assembly                               ",
         "<Complaint>Seat belt buckle open circuit </Complaint><Cause>Faulty buckle </Cause><Correction>tech replaced seat belt latch driver side, reset codes. no codes returned after repair , repair successful </Correction><Estimate></Estimate><Notes>3/4/25 tech replaced seat belt latch driver side, reset codes. no codes returned after repair , repair successful </Notes>",
         "LABOR       ",
         "1.0",
         "0",
         "110.0",
         "110.0"
        ],
        [
         "4",
         "12482815",
         "REPAIR      ",
         "2025-03-05 04:17:00",
         "002-011-003 ",
         "Seat Belt & Retainer Assembly                               ",
         "<Complaint>Seat belt buckle open circuit </Complaint><Cause>Faulty buckle </Cause><Correction>tech replaced seat belt latch driver side, reset codes. no codes returned after repair , repair successful </Correction><Estimate></Estimate><Notes>3/4/25 tech replaced seat belt latch driver side, reset codes. no codes returned after repair , repair successful </Notes>",
         "PART        ",
         "0.0",
         "1",
         "134.85",
         "134.85"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orderid</th>\n",
       "      <th>Orderstatus</th>\n",
       "      <th>Completedate</th>\n",
       "      <th>Compcode</th>\n",
       "      <th>Compcodedescrip</th>\n",
       "      <th>Sectioncomments</th>\n",
       "      <th>Linetype</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Unitcst</th>\n",
       "      <th>linetotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12383330</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>2025-03-05 16:23:00</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "      <td>&lt;Complaint&gt;Seatbelt&lt;/Complaint&gt;&lt;Cause&gt;Check va...</td>\n",
       "      <td>LABOR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12383330</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>2025-03-05 16:23:00</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "      <td>&lt;Complaint&gt;Seatbelt&lt;/Complaint&gt;&lt;Cause&gt;Check va...</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>369.70</td>\n",
       "      <td>369.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12383330</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>2025-03-05 16:23:00</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "      <td>&lt;Complaint&gt;Seatbelt&lt;/Complaint&gt;&lt;Cause&gt;Check va...</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>142.10</td>\n",
       "      <td>142.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12482815</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>2025-03-05 04:17:00</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "      <td>&lt;Complaint&gt;Seat belt buckle open circuit &lt;/Com...</td>\n",
       "      <td>LABOR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12482815</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>2025-03-05 04:17:00</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "      <td>&lt;Complaint&gt;Seat belt buckle open circuit &lt;/Com...</td>\n",
       "      <td>PART</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>134.85</td>\n",
       "      <td>134.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    orderid   Orderstatus        Completedate      Compcode                                    Compcodedescrip                                    Sectioncomments      Linetype  Hours  Qty  Unitcst  linetotal\n",
       "0  12383330  REPAIR       2025-03-05 16:23:00  002-011-003   Seat Belt & Retainer Assembly                 ...  <Complaint>Seatbelt</Complaint><Cause>Check va...  LABOR           1.0    0   110.00     110.00\n",
       "1  12383330  REPAIR       2025-03-05 16:23:00  002-011-003   Seat Belt & Retainer Assembly                 ...  <Complaint>Seatbelt</Complaint><Cause>Check va...  PART            0.0    1   369.70     369.70\n",
       "2  12383330  REPAIR       2025-03-05 16:23:00  002-011-003   Seat Belt & Retainer Assembly                 ...  <Complaint>Seatbelt</Complaint><Cause>Check va...  PART            0.0    1   142.10     142.10\n",
       "3  12482815  REPAIR       2025-03-05 04:17:00  002-011-003   Seat Belt & Retainer Assembly                 ...  <Complaint>Seat belt buckle open circuit </Com...  LABOR           1.0    0   110.00     110.00\n",
       "4  12482815  REPAIR       2025-03-05 04:17:00  002-011-003   Seat Belt & Retainer Assembly                 ...  <Complaint>Seat belt buckle open circuit </Com...  PART            0.0    1   134.85     134.85"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Excel file\n",
    "file_path = \"Lm_orders_seatbelt_v2.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"File: {file_path}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n",
    "print(\"\\nColumn names:\")\n",
    "for col in df.columns:\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "# Show the first few rows\n",
    "print(\"\\nFirst 5 rows of data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77b4a9",
   "metadata": {},
   "source": [
    "## Data Exploration and Preparation\n",
    "\n",
    "Before creating our vector database, let's analyze the \"Sectioncomments\" column that we'll be indexing to better understand our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45a9f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Sectioncomments: 0 (0.00%)\n",
      "\n",
      "Comment length statistics:\n",
      "Min: 159 characters\n",
      "Max: 1696 characters\n",
      "Mean: 401.57 characters\n",
      "Median: 310.0 characters\n",
      "\n",
      "Sample comments:\n",
      "\n",
      "Medium comment (182 chars):\n",
      "<Correction>Replace seatbelt buckle</Correction><Notes></Notes><Cause>Casing missing off of buckle</Cause><Complaint>Seatbelt buckle broken</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "Long comment (1696 chars):\n",
      "<Correction>Tech 18823 warning light goes on for seat belt DSP complaint upon inspection confirmed DSP complaint will repair as per above diagnostics remove trim panel to gain access to failed seat belt remove upper shoulder harness and unbolt remove bolt from seatbelt assembly disconnect SRS from failed seat belt install new seat belt reconnect SRS assemble trim panel check and confirm job complete</Correction><Notes>Tech 18823 warning light goes on for seat belt DSP complaint upon inspection confirmed DSP complaint will repair as per above diagnostics remove trim panel to gain access to failed seat belt remove upper shoulder harness and unbolt remove bolt from seatbelt assembly disconnect SRS from failed seat belt install new seat belt reconnect SRS assemble trim panel check and confirm job complete Please add seat belt to RO</Notes><Cause>Tech 18823 warning light goes on for seat belt DSP complaint upon inspection confirmed DSP complaint will repair as per above diagnostics remove trim panel to gain access to failed seat belt remove upper shoulder harness and unbolt remove bolt from seatbelt assembly disconnect SRS from failed seat belt install new seat belt reconnect SRS assemble trim panel check and confirm job complete</Cause><Complaint>Tech 18823 warning light goes on for seat belt DSP complaint upon inspection confirmed DSP complaint will repair as per above diagnostics remove trim panel to gain access to failed seat belt remove upper shoulder harness and unbolt remove bolt from seatbelt assembly disconnect SRS from failed seat belt install new seat belt reconnect SRS assemble trim panel check and confirm job complete</Complaint><CauseOfRepair></CauseOfRepair>\n"
     ]
    }
   ],
   "source": [
    "# Explore the \"Sectioncomments\" column that we'll be indexing\n",
    "if \"Sectioncomments\" in df.columns:\n",
    "    # Check for missing values\n",
    "    missing_comments = df[\"Sectioncomments\"].isna().sum()\n",
    "    print(f\"Number of missing values in Sectioncomments: {missing_comments} ({missing_comments/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Get statistics on comment length\n",
    "    df[\"comment_length\"] = df[\"Sectioncomments\"].astype(str).apply(len)\n",
    "    print(f\"\\nComment length statistics:\")\n",
    "    print(f\"Min: {df['comment_length'].min()} characters\")\n",
    "    print(f\"Max: {df['comment_length'].max()} characters\")\n",
    "    print(f\"Mean: {df['comment_length'].mean():.2f} characters\")\n",
    "    print(f\"Median: {df['comment_length'].median()} characters\")\n",
    "    \n",
    "    # Display some sample comments of different lengths\n",
    "    print(\"\\nSample comments:\")\n",
    "    \n",
    "    # Short comment (if available)\n",
    "    short_comments = df[df[\"comment_length\"] < 50].sort_values(\"comment_length\")\n",
    "    if not short_comments.empty:\n",
    "        idx = short_comments.index[0]\n",
    "        print(f\"\\nShort comment ({df.loc[idx, 'comment_length']} chars):\")\n",
    "        print(df.loc[idx, \"Sectioncomments\"])\n",
    "    \n",
    "    # Medium comment\n",
    "    med_comments = df[(df[\"comment_length\"] >= 50) & (df[\"comment_length\"] < 200)]\n",
    "    if not med_comments.empty:\n",
    "        idx = med_comments.index[0]\n",
    "        print(f\"\\nMedium comment ({df.loc[idx, 'comment_length']} chars):\")\n",
    "        print(df.loc[idx, \"Sectioncomments\"])\n",
    "    \n",
    "    # Long comment\n",
    "    long_comments = df[df[\"comment_length\"] >= 200].sort_values(\"comment_length\", ascending=False)\n",
    "    if not long_comments.empty:\n",
    "        idx = long_comments.index[0]\n",
    "        print(f\"\\nLong comment ({df.loc[idx, 'comment_length']} chars):\")\n",
    "        print(df.loc[idx, \"Sectioncomments\"])\n",
    "else:\n",
    "    print(\"Column 'Sectioncomments' not found in the dataset. Available columns:\")\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bf527",
   "metadata": {},
   "source": [
    "## Creating a Vector Database\n",
    "\n",
    "Now we'll create a vector database using:\n",
    "1. **ChromaDB** as our vector store\n",
    "2. **OpenAI Embeddings** to convert text into vector embeddings\n",
    "3. **LangChain** to tie everything together\n",
    "\n",
    "We'll index only the \"Sectioncomments\" column, while keeping the other columns as metadata for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2ee7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI API key is set\n",
      "âœ… Using embedding model: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if the OpenAI API key is set\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding_model = os.getenv(\"EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "\n",
    "if openai_api_key == \"your_openai_api_key_here\" or not openai_api_key:\n",
    "    print(\"âš ï¸ WARNING: You need to set your OpenAI API key in the .env file!\")\n",
    "    print(\"Please update the .env file with your actual API key.\")\n",
    "else:\n",
    "    print(f\"âœ… OpenAI API key is set\")\n",
    "    print(f\"âœ… Using embedding model: {embedding_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4200ba0e",
   "metadata": {},
   "source": [
    "## Vector Database Structure Verification\n",
    "\n",
    "Let's verify the structure of our vector database to confirm it's correctly storing embeddings for \"Sectioncomments\" only, with all other columns as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79b3f5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Vector Database Structure Explanation\n",
       "\n",
       "```\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚                      Vector Database                         â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "               â”‚                         â”‚\n",
       "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚       Embeddings            â”‚ â”‚        Metadata            â”‚\n",
       "â”‚ (from \"Sectioncomments\")    â”‚ â”‚  (all other columns)       â”‚\n",
       "â”‚                             â”‚ â”‚                            â”‚\n",
       "â”‚ â€¢ Dense vectors             â”‚ â”‚ â€¢ Row ID                   â”‚\n",
       "â”‚ â€¢ High-dimensional space    â”‚ â”‚ â€¢ Vehicle info             â”‚\n",
       "â”‚ â€¢ Capture semantic meaning  â”‚ â”‚ â€¢ Timestamps               â”‚\n",
       "â”‚                             â”‚ â”‚ â€¢ Any other columns        â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "               â”‚                          â”‚\n",
       "               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "                          â”‚\n",
       "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "          â”‚       Search Process           â”‚\n",
       "          â”‚                                â”‚\n",
       "          â”‚ 1. Query is embedded           â”‚\n",
       "          â”‚ 2. Find similar embeddings     â”‚\n",
       "          â”‚ 3. Return matched documents    â”‚\n",
       "          â”‚    with their metadata         â”‚\n",
       "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "```\n",
       "\n",
       "**Important points:**\n",
       "1. Only the \"Sectioncomments\" text is converted to embeddings\n",
       "2. All other columns are stored as metadata (not embedded)\n",
       "3. Searches match against embedded \"Sectioncomments\" only\n",
       "4. Search results include both the matching comment and all metadata\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a visual diagram explaining the vector database structure\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "explanation = \"\"\"\n",
    "## Vector Database Structure Explanation\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                      Vector Database                         â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚                         â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚       Embeddings            â”‚ â”‚        Metadata            â”‚\n",
    "â”‚ (from \"Sectioncomments\")    â”‚ â”‚  (all other columns)       â”‚\n",
    "â”‚                             â”‚ â”‚                            â”‚\n",
    "â”‚ â€¢ Dense vectors             â”‚ â”‚ â€¢ Row ID                   â”‚\n",
    "â”‚ â€¢ High-dimensional space    â”‚ â”‚ â€¢ Vehicle info             â”‚\n",
    "â”‚ â€¢ Capture semantic meaning  â”‚ â”‚ â€¢ Timestamps               â”‚\n",
    "â”‚                             â”‚ â”‚ â€¢ Any other columns        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "               â”‚                          â”‚\n",
    "               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                          â”‚\n",
    "          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "          â”‚       Search Process           â”‚\n",
    "          â”‚                                â”‚\n",
    "          â”‚ 1. Query is embedded           â”‚\n",
    "          â”‚ 2. Find similar embeddings     â”‚\n",
    "          â”‚ 3. Return matched documents    â”‚\n",
    "          â”‚    with their metadata         â”‚\n",
    "          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Important points:**\n",
    "1. Only the \"Sectioncomments\" text is converted to embeddings\n",
    "2. All other columns are stored as metadata (not embedded)\n",
    "3. Searches match against embedded \"Sectioncomments\" only\n",
    "4. Search results include both the matching comment and all metadata\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(explanation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b9c70d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… langchain is already installed\n",
      "âœ… langchain_chroma is already installed\n",
      "âœ… chromadb is already installed\n",
      "âœ… langchain_openai is already installed\n",
      "ğŸ“¦ Installing python-dotenv...\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.13/site-packages (1.1.1)\n",
      "\n",
      "âœ… All required libraries are available!\n",
      "\n",
      "âœ… All required libraries are available!\n"
     ]
    }
   ],
   "source": [
    "# Check and install required libraries\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"ğŸ“¦ Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Check required libraries\n",
    "required_libs = [\n",
    "    'langchain',\n",
    "    'langchain_chroma', \n",
    "    'chromadb',\n",
    "    'langchain_openai',\n",
    "    'python-dotenv'\n",
    "]\n",
    "\n",
    "for lib in required_libs:\n",
    "    install_if_missing(lib)\n",
    "\n",
    "print(\"\\nâœ… All required libraries are available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "592ea6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector database configuration:\n",
      "   - Collection name: seatbelt_comments\n",
      "   - Persist directory: /Users/ahb/CaylentDocs/Projects/AmeritFleetSolutions-AIStrategy/SampleData/chroma_db\n",
      "   - Current working directory: /Users/ahb/CaylentDocs/Projects/AmeritFleetSolutions-AIStrategy/SampleData\n",
      "   - Embedding model: text-embedding-3-small\n",
      "   - Default similarity threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries for vector database\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import tempfile\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "COLLECTION_NAME = \"seatbelt_comments\"\n",
    "# Ensure vector database is stored in the current working directory\n",
    "import os\n",
    "PERSIST_DIRECTORY = os.path.join(os.getcwd(), \"chroma_db\")\n",
    "SIMILARITY_THRESHOLD = 0.7  # Default threshold, can be modified by user\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=embedding_model,\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "print(f\"âœ… Vector database configuration:\")\n",
    "print(f\"   - Collection name: {COLLECTION_NAME}\")\n",
    "print(f\"   - Persist directory: {PERSIST_DIRECTORY}\")\n",
    "print(f\"   - Current working directory: {os.getcwd()}\")\n",
    "print(f\"   - Embedding model: {embedding_model}\")\n",
    "print(f\"   - Default similarity threshold: {SIMILARITY_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85dafce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Using existing vector database from current session\n"
     ]
    }
   ],
   "source": [
    "# Function to create or load vector database\n",
    "def create_or_load_vectordb():\n",
    "    \"\"\"Create a new vector database or load existing one\"\"\"\n",
    "    \n",
    "    # Use a temporary directory approach to avoid settings conflicts\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    # Try to connect to existing database or create new one\n",
    "    try:\n",
    "        # Check if vectordb already exists in current scope\n",
    "        try:\n",
    "            # Try to access existing vectordb from globals\n",
    "            existing_db = globals().get('vectordb')\n",
    "            if existing_db is not None:\n",
    "                print(\"ğŸ”„ Using existing vector database from current session\")\n",
    "                collection_count = existing_db._collection.count()\n",
    "                return existing_db, collection_count == 0\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Create new vector database\n",
    "        print(\"ğŸ“ Creating new vector database...\")\n",
    "        vectordb = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=PERSIST_DIRECTORY\n",
    "        )\n",
    "        \n",
    "        # Check if collection has any documents\n",
    "        collection_count = vectordb._collection.count()\n",
    "        \n",
    "        if collection_count > 0:\n",
    "            print(f\"âœ… Loaded existing vector database with {collection_count} documents\")\n",
    "            return vectordb, False  # False indicates it's not empty\n",
    "        else:\n",
    "            print(f\"ğŸ“Š Found empty vector database, will populate with data\")\n",
    "            return vectordb, True  # True indicates it's empty\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Database connection issue: {e}\")\n",
    "        print(\"ğŸ”„ Using temporary database for this session...\")\n",
    "        \n",
    "        # Use a temporary directory\n",
    "        temp_dir = tempfile.mkdtemp()\n",
    "        vectordb = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=temp_dir\n",
    "        )\n",
    "        print(f\"ğŸ“ Temporary database created at: {temp_dir}\")\n",
    "        return vectordb, True  # True indicates it's empty\n",
    "\n",
    "# Create or load the database\n",
    "vectordb, is_empty = create_or_load_vectordb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dc3760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking vector database location...\n",
      "   - Expected path: /Users/ahb/CaylentDocs/Projects/AmeritFleetSolutions-AIStrategy/SampleData/chroma_db\n",
      "   - Directory exists: True\n",
      "   - Current vectordb path: None\n",
      "âš ï¸ Vector database is not in the current directory\n",
      "ğŸ”„ Recreating database in current directory...\n",
      "âœ… Database recreated with 237 documents\n"
     ]
    }
   ],
   "source": [
    "# Verify vector database location and recreate if needed\n",
    "def ensure_vectordb_in_current_directory():\n",
    "    \"\"\"Ensure the vector database is stored in the current directory\"\"\"\n",
    "    import os\n",
    "    \n",
    "    current_dir = os.getcwd()\n",
    "    expected_db_path = os.path.join(current_dir, os.path.basename(PERSIST_DIRECTORY))\n",
    "    \n",
    "    print(f\"ğŸ” Checking vector database location...\")\n",
    "    print(f\"   - Expected path: {expected_db_path}\")\n",
    "    print(f\"   - Directory exists: {os.path.exists(expected_db_path)}\")\n",
    "    \n",
    "    # Check if current vectordb is using the correct directory\n",
    "    if 'vectordb' in globals():\n",
    "        try:\n",
    "            current_persist_dir = getattr(vectordb._client, 'path', None)\n",
    "            print(f\"   - Current vectordb path: {current_persist_dir}\")\n",
    "            \n",
    "            # If the database is not in the expected location, recreate it\n",
    "            if current_persist_dir != expected_db_path:\n",
    "                print(f\"âš ï¸ Vector database is not in the current directory\")\n",
    "                print(f\"ğŸ”„ Recreating database in current directory...\")\n",
    "                \n",
    "                # Create new database in correct location\n",
    "                new_vectordb = Chroma(\n",
    "                    collection_name=COLLECTION_NAME,\n",
    "                    embedding_function=embeddings,\n",
    "                    persist_directory=PERSIST_DIRECTORY\n",
    "                )\n",
    "                \n",
    "                # If old database had data, we'll need to re-populate\n",
    "                old_count = vectordb._collection.count()\n",
    "                new_count = new_vectordb._collection.count()\n",
    "                \n",
    "                if old_count > 0 and new_count == 0:\n",
    "                    print(f\"ğŸ“‹ Old database had {old_count} documents, will need re-population\")\n",
    "                    return new_vectordb, True  # Needs population\n",
    "                else:\n",
    "                    print(f\"âœ… Database recreated with {new_count} documents\")\n",
    "                    return new_vectordb, False  # Already has data\n",
    "            else:\n",
    "                print(f\"âœ… Vector database is already in the correct location\")\n",
    "                return vectordb, False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error checking database location: {e}\")\n",
    "            print(f\"ğŸ”„ Creating new database in current directory...\")\n",
    "            new_vectordb = Chroma(\n",
    "                collection_name=COLLECTION_NAME,\n",
    "                embedding_function=embeddings,\n",
    "                persist_directory=PERSIST_DIRECTORY\n",
    "            )\n",
    "            return new_vectordb, True\n",
    "    else:\n",
    "        print(f\"ğŸ“ Creating new vector database in current directory...\")\n",
    "        new_vectordb = Chroma(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            embedding_function=embeddings,\n",
    "            persist_directory=PERSIST_DIRECTORY\n",
    "        )\n",
    "        return new_vectordb, True\n",
    "\n",
    "# Ensure database is in current directory\n",
    "vectordb, needs_population = ensure_vectordb_in_current_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "358620d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Database already contains data. Skipping data addition.\n",
      "ğŸ’¡ To force re-indexing, delete the chroma_db folder and run again.\n"
     ]
    }
   ],
   "source": [
    "# Function to add Excel data to vector database\n",
    "def add_excel_data_to_vectordb(df, vectordb):\n",
    "    \"\"\"Add Excel data to vector database, embedding only Sectioncomments\"\"\"\n",
    "    \n",
    "    # Filter out rows with missing Sectioncomments\n",
    "    df_filtered = df.dropna(subset=['Sectioncomments']).copy()\n",
    "    \n",
    "    # Convert Sectioncomments to string and filter out very short comments\n",
    "    df_filtered['Sectioncomments'] = df_filtered['Sectioncomments'].astype(str)\n",
    "    df_filtered = df_filtered[df_filtered['Sectioncomments'].str.len() > 10]  # Minimum 10 characters\n",
    "    \n",
    "    print(f\"ğŸ“Š Processing {len(df_filtered)} records with valid comments...\")\n",
    "    \n",
    "    # Prepare documents\n",
    "    documents = []\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "        # Create metadata from all columns except Sectioncomments\n",
    "        metadata = {}\n",
    "        for col in df_filtered.columns:\n",
    "            if col != 'Sectioncomments':\n",
    "                value = row[col]\n",
    "                # Handle different data types for metadata\n",
    "                if pd.isna(value):\n",
    "                    metadata[col] = None\n",
    "                elif isinstance(value, (pd.Timestamp, datetime)):\n",
    "                    metadata[col] = value.isoformat() if not pd.isna(value) else None\n",
    "                else:\n",
    "                    metadata[col] = str(value)\n",
    "        \n",
    "        # Add row index for unique identification\n",
    "        metadata['row_index'] = int(idx)\n",
    "        \n",
    "        # Create document with Sectioncomments as content and everything else as metadata\n",
    "        doc = Document(\n",
    "            page_content=str(row['Sectioncomments']),\n",
    "            metadata=metadata\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    # Add documents to vector database in batches\n",
    "    batch_size = 50\n",
    "    total_added = 0\n",
    "    \n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i + batch_size]\n",
    "        vectordb.add_documents(batch)\n",
    "        total_added += len(batch)\n",
    "        print(f\"âœ… Added batch {i//batch_size + 1}: {total_added}/{len(documents)} documents\")\n",
    "    \n",
    "    print(f\"ğŸ‰ Successfully added {total_added} documents to vector database!\")\n",
    "    return total_added\n",
    "\n",
    "# Add data if database is empty or needs population\n",
    "if is_empty or needs_population:\n",
    "    print(\"ğŸ“ Adding Excel data to vector database...\")\n",
    "    total_added = add_excel_data_to_vectordb(df, vectordb)\n",
    "else:\n",
    "    print(\"ğŸ“Š Database already contains data. Skipping data addition.\")\n",
    "    print(f\"ğŸ’¡ To force re-indexing, delete the {os.path.basename(PERSIST_DIRECTORY)} folder and run again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1816617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ LCEL Pipeline created successfully!\n",
      "ğŸ’¡ Use semantic_search_with_ranking(query, k, similarity_threshold) to search\n"
     ]
    }
   ],
   "source": [
    "# Create LCEL pipeline for semantic search with date ranking and similarity threshold\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "def parse_date_from_metadata(metadata):\n",
    "    \"\"\"Extract and parse date from metadata for sorting\"\"\"\n",
    "    # Look for common date fields\n",
    "    date_fields = ['date', 'Date', 'created_date', 'timestamp', 'created_at', 'Date Time']\n",
    "    \n",
    "    for field in date_fields:\n",
    "        if field in metadata and metadata[field]:\n",
    "            try:\n",
    "                date_str = str(metadata[field])\n",
    "                # Try parsing ISO format first\n",
    "                if 'T' in date_str:\n",
    "                    return datetime.fromisoformat(date_str.replace('Z', '+00:00'))\n",
    "                # Try other common formats\n",
    "                for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d', '%m/%d/%Y', '%d/%m/%Y']:\n",
    "                    try:\n",
    "                        return datetime.strptime(date_str, fmt)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # If no date found, return a very old date for sorting\n",
    "    return datetime(1900, 1, 1)\n",
    "\n",
    "def filter_and_rank_results(results_with_scores, similarity_threshold=SIMILARITY_THRESHOLD):\n",
    "    \"\"\"Filter results by similarity threshold and rank by date descending\"\"\"\n",
    "    \n",
    "    # Filter by similarity threshold\n",
    "    filtered_results = [\n",
    "        (doc, score) for doc, score in results_with_scores \n",
    "        if score >= similarity_threshold\n",
    "    ]\n",
    "    \n",
    "    if not filtered_results:\n",
    "        return []\n",
    "    \n",
    "    # Sort by date descending (most recent first)\n",
    "    def get_sort_key(doc_score_tuple):\n",
    "        doc, score = doc_score_tuple\n",
    "        date = parse_date_from_metadata(doc.metadata)\n",
    "        return (date, score)  # Sort by date first, then by score\n",
    "    \n",
    "    sorted_results = sorted(filtered_results, key=get_sort_key, reverse=True)\n",
    "    \n",
    "    return sorted_results\n",
    "\n",
    "def semantic_search_with_ranking(query: str, k: int = 10, similarity_threshold: float = SIMILARITY_THRESHOLD):\n",
    "    \"\"\"\n",
    "    Perform semantic search with date ranking and similarity threshold filtering\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query\n",
    "        k (int): Number of results to retrieve initially (before filtering)\n",
    "        similarity_threshold (float): Minimum similarity score (0.0 to 1.0)\n",
    "    \n",
    "    Returns:\n",
    "        list: Filtered and ranked results\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Searching for: '{query}'\")\n",
    "    print(f\"ğŸ“Š Similarity threshold: {similarity_threshold}\")\n",
    "    print(f\"ğŸ“… Results will be ranked by date (newest first)\")\n",
    "    \n",
    "    # Perform similarity search with scores\n",
    "    results_with_scores = vectordb.similarity_search_with_score(query, k=k*2)  # Get more to account for filtering\n",
    "    \n",
    "    # Filter and rank results\n",
    "    final_results = filter_and_rank_results(results_with_scores, similarity_threshold)\n",
    "    \n",
    "    # Limit to requested number\n",
    "    final_results = final_results[:k]\n",
    "    \n",
    "    print(f\"âœ… Found {len(final_results)} results above threshold {similarity_threshold}\")\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "# Create the LCEL pipeline\n",
    "search_pipeline = RunnableLambda(semantic_search_with_ranking)\n",
    "\n",
    "print(\"ğŸš€ LCEL Pipeline created successfully!\")\n",
    "print(\"ğŸ’¡ Use semantic_search_with_ranking(query, k, similarity_threshold) to search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0969c",
   "metadata": {},
   "source": [
    "## Demonstration of Semantic Search Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd21e6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b3f3104",
   "metadata": {},
   "source": [
    "### Complete end-to-end search demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77df39d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Complete Search Demonstration\n",
      "==================================================\n",
      "ğŸ” Searching for: 'broken seatbelt needs replacement'\n",
      "ğŸ“‹ This will show results in both original format and structured table format\n",
      "ğŸ” Searching for: 'broken seatbelt needs replacement'\n",
      "ğŸ“Š Similarity threshold: 0.6\n",
      "ğŸ“… Results will be ranked by date (newest first)\n",
      "âœ… Found 3 results above threshold 0.6\n",
      "\n",
      "ğŸ“Š Found 3 relevant results\n",
      "============================================================\n",
      "ğŸ“‹ Results in ORIGINAL DETAILED FORMAT:\n",
      "============================================================\n",
      "\n",
      "ğŸ† Result #1 (Similarity Score: 0.654)\n",
      "----------------------------------------\n",
      "ğŸ’¬ Comment: <Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complai...\n",
      "ğŸ“ Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Completedate: 2025-06-20T10:12:00\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Qty: 1\n",
      "   â€¢ Unitcst: 291.95\n",
      "   â€¢ Comment Length: 184 characters\n",
      "   â€¢ Row Index: 218\n",
      "\n",
      "ğŸ† Result #2 (Similarity Score: 0.654)\n",
      "----------------------------------------\n",
      "ğŸ’¬ Comment: <Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complai...\n",
      "ğŸ“ Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Completedate: 2025-06-20T10:12:00\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Qty: 0\n",
      "   â€¢ Unitcst: 110.0\n",
      "   â€¢ Comment Length: 184 characters\n",
      "   â€¢ Row Index: 219\n",
      "\n",
      "ğŸ† Result #3 (Similarity Score: 0.649)\n",
      "----------------------------------------\n",
      "ğŸ’¬ Comment: <Correction>Replaced Seat Belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complai...\n",
      "ğŸ“ Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Completedate: 2025-05-07T10:28:00\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Qty: 0\n",
      "   â€¢ Unitcst: 110.0\n",
      "   â€¢ Comment Length: 184 characters\n",
      "   â€¢ Row Index: 114\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Same results in STRUCTURED TABLE FORMAT:\n",
      "============================================================\n",
      "âœ… Found 3 results above threshold 0.6\n",
      "\n",
      "ğŸ“Š Found 3 relevant results\n",
      "============================================================\n",
      "ğŸ“‹ Results in ORIGINAL DETAILED FORMAT:\n",
      "============================================================\n",
      "\n",
      "ğŸ† Result #1 (Similarity Score: 0.654)\n",
      "----------------------------------------\n",
      "ğŸ’¬ Comment: <Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complai...\n",
      "ğŸ“ Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Completedate: 2025-06-20T10:12:00\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Qty: 1\n",
      "   â€¢ Unitcst: 291.95\n",
      "   â€¢ Comment Length: 184 characters\n",
      "   â€¢ Row Index: 218\n",
      "\n",
      "ğŸ† Result #2 (Similarity Score: 0.654)\n",
      "----------------------------------------\n",
      "ğŸ’¬ Comment: <Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complai...\n",
      "ğŸ“ Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Completedate: 2025-06-20T10:12:00\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Qty: 0\n",
      "   â€¢ Unitcst: 110.0\n",
      "   â€¢ Comment Length: 184 characters\n",
      "   â€¢ Row Index: 219\n",
      "\n",
      "ğŸ† Result #3 (Similarity Score: 0.649)\n",
      "----------------------------------------\n",
      "ğŸ’¬ Comment: <Correction>Replaced Seat Belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complai...\n",
      "ğŸ“ Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Completedate: 2025-05-07T10:28:00\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Qty: 0\n",
      "   â€¢ Unitcst: 110.0\n",
      "   â€¢ Comment Length: 184 characters\n",
      "   â€¢ Row Index: 114\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š Same results in STRUCTURED TABLE FORMAT:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Result #",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Similarity Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comment Preview",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Cost",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comment Length",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "c4c303dc-4cbf-46eb-bf8e-3492f614e406",
       "rows": [
        [
         "0",
         "1",
         "0.654",
         "<Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs repla...",
         "2025-06-20T10:12:00",
         "REPAIR      ",
         "291.95",
         "002-011-003 ",
         "184"
        ],
        [
         "1",
         "2",
         "0.654",
         "<Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs repla...",
         "2025-06-20T10:12:00",
         "REPAIR      ",
         "110.0",
         "002-011-003 ",
         "184"
        ],
        [
         "2",
         "3",
         "0.649",
         "<Correction>Replaced Seat Belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs repla...",
         "2025-05-07T10:28:00",
         "REPAIR      ",
         "110.0",
         "002-011-003 ",
         "184"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result #</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Comment Preview</th>\n",
       "      <th>Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Code</th>\n",
       "      <th>Comment Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.654</td>\n",
       "      <td>&lt;Correction&gt;Replaced Seat belt&lt;/Correction&gt;&lt;No...</td>\n",
       "      <td>2025-06-20T10:12:00</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>291.95</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.654</td>\n",
       "      <td>&lt;Correction&gt;Replaced Seat belt&lt;/Correction&gt;&lt;No...</td>\n",
       "      <td>2025-06-20T10:12:00</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>110.0</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.649</td>\n",
       "      <td>&lt;Correction&gt;Replaced Seat Belt&lt;/Correction&gt;&lt;No...</td>\n",
       "      <td>2025-05-07T10:28:00</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>110.0</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result # Similarity Score                                    Comment Preview                 Date        Status    Cost          Code Comment Length\n",
       "0         1            0.654  <Correction>Replaced Seat belt</Correction><No...  2025-06-20T10:12:00  REPAIR        291.95  002-011-003             184\n",
       "1         2            0.654  <Correction>Replaced Seat belt</Correction><No...  2025-06-20T10:12:00  REPAIR         110.0  002-011-003             184\n",
       "2         3            0.649  <Correction>Replaced Seat Belt</Correction><No...  2025-05-07T10:28:00  REPAIR         110.0  002-011-003             184"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Detailed Results with All Metadata:\n",
      "============================================================\n",
      "\n",
      "ğŸ“„ Result #1 Details:\n",
      "----------------------------------------\n",
      "ğŸ¯ Similarity Score: 0.654\n",
      "\n",
      "ğŸ’¬ Full Comment:\n",
      "   <Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "ğŸ“ Complete Metadata:\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Hours: 0.0\n",
      "   â€¢ Qty: 1\n",
      "   â€¢ Compcodedescrip: Seat Belt & Retainer Assembly                               \n",
      "   â€¢ Linetotal: 291.95\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Comment Length: 184\n",
      "   â€¢ Linetype: PART        \n",
      "   â€¢ Row Index: 218\n",
      "   â€¢ Orderid: 13176686\n",
      "   â€¢ Unitcst: 291.95\n",
      "   â€¢ Completedate: 2025-06-20T10:12:00\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ Result #2 Details:\n",
      "----------------------------------------\n",
      "ğŸ¯ Similarity Score: 0.654\n",
      "\n",
      "ğŸ’¬ Full Comment:\n",
      "   <Correction>Replaced Seat belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "ğŸ“ Complete Metadata:\n",
      "   â€¢ Linetype: LABOR       \n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Linetotal: 110.0\n",
      "   â€¢ Comment Length: 184\n",
      "   â€¢ Compcodedescrip: Seat Belt & Retainer Assembly                               \n",
      "   â€¢ Hours: 1.0\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Unitcst: 110.0\n",
      "   â€¢ Completedate: 2025-06-20T10:12:00\n",
      "   â€¢ Orderid: 13176686\n",
      "   â€¢ Row Index: 219\n",
      "   â€¢ Qty: 0\n",
      "----------------------------------------\n",
      "\n",
      "ğŸ“„ Result #3 Details:\n",
      "----------------------------------------\n",
      "ğŸ¯ Similarity Score: 0.649\n",
      "\n",
      "ğŸ’¬ Full Comment:\n",
      "   <Correction>Replaced Seat Belt</Correction><Notes></Notes><Cause>Seat belt is frayed and needs replaced</Cause><Complaint>Mechanic Inspection</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "ğŸ“ Complete Metadata:\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Orderid: 12854281\n",
      "   â€¢ Compcodedescrip: Seat Belt & Retainer Assembly                               \n",
      "   â€¢ Completedate: 2025-05-07T10:28:00\n",
      "   â€¢ Linetype: LABOR       \n",
      "   â€¢ Unitcst: 110.0\n",
      "   â€¢ Hours: 1.5\n",
      "   â€¢ Qty: 0\n",
      "   â€¢ Row Index: 114\n",
      "   â€¢ Comment Length: 184\n",
      "   â€¢ Linetotal: 165.0\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "----------------------------------------\n",
      "\n",
      "================================================================================\n",
      "âœ… End-to-end search demonstration complete!\n",
      "ğŸ’¡ The system successfully:\n",
      "   - Embedded the query using OpenAI\n",
      "   - Searched the vector database\n",
      "   - Applied similarity threshold filtering\n",
      "   - Ranked results appropriately\n",
      "   - Returned complete records with metadata\n",
      "   - Displayed results in both original and table formats\n"
     ]
    }
   ],
   "source": [
    "# Complete end-to-end search demonstration with structured table display\n",
    "print(\"ğŸ¯ Complete Search Demonstration\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Perform a realistic search\n",
    "query = \"broken seatbelt needs replacement\"\n",
    "print(f\"ğŸ” Searching for: '{query}'\")\n",
    "print(f\"ğŸ“‹ This will show results in both original format and structured table format\")\n",
    "\n",
    "# Get results with moderate threshold (slightly lower than default for demo)\n",
    "demo_threshold = SIMILARITY_THRESHOLD - 0.1\n",
    "results = semantic_search_with_ranking(query, k=3, similarity_threshold=demo_threshold)\n",
    "\n",
    "# Display detailed results in original format\n",
    "if results:\n",
    "    print(f\"\\nğŸ“Š Found {len(results)} relevant results\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ“‹ Results in ORIGINAL DETAILED FORMAT:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\nğŸ† Result #{i} (Similarity Score: {score:.3f})\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Show the comment content\n",
    "        comment = doc.page_content\n",
    "        print(f\"ğŸ’¬ Comment: {comment[:150]}{'...' if len(comment) > 150 else ''}\")\n",
    "        \n",
    "        # Show relevant metadata\n",
    "        metadata = doc.metadata\n",
    "        print(f\"ğŸ“ Metadata:\")\n",
    "        \n",
    "        # Show key fields if they exist\n",
    "        key_fields = ['Compcode', 'Completedate', 'Orderstatus', 'Qty', 'Unitcst']\n",
    "        for field in key_fields:\n",
    "            if field in metadata and metadata[field] and str(metadata[field]) != 'nan':\n",
    "                print(f\"   â€¢ {field}: {metadata[field]}\")\n",
    "        \n",
    "        print(f\"   â€¢ Comment Length: {metadata.get('comment_length', 'N/A')} characters\")\n",
    "        print(f\"   â€¢ Row Index: {metadata.get('row_index', 'N/A')}\")\n",
    "    \n",
    "    # Now display same results in structured table format using pandas\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ“Š Same results in STRUCTURED TABLE FORMAT:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create a simple table using pandas for basic semantic search results\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "    \n",
    "    table_data = []\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        metadata = doc.metadata\n",
    "        row = {\n",
    "            'Result #': i,\n",
    "            'Similarity Score': f\"{score:.3f}\",\n",
    "            'Comment Preview': doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content,\n",
    "            'Date': metadata.get('Completedate', 'N/A'),\n",
    "            'Status': metadata.get('Orderstatus', 'N/A'),\n",
    "            'Cost': metadata.get('Unitcst', 'N/A'),\n",
    "            'Code': metadata.get('Compcode', 'N/A'),\n",
    "            'Comment Length': metadata.get('comment_length', 'N/A')\n",
    "        }\n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Create and display DataFrame\n",
    "    df_results = pd.DataFrame(table_data)\n",
    "    display(df_results)\n",
    "    \n",
    "    # Also show detailed view for each result\n",
    "    print(f\"\\nğŸ“‹ Detailed Results with All Metadata:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        metadata = doc.metadata\n",
    "        \n",
    "        print(f\"\\nğŸ“„ Result #{i} Details:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"ğŸ¯ Similarity Score: {score:.3f}\")\n",
    "        \n",
    "        # Full comment\n",
    "        print(f\"\\nğŸ’¬ Full Comment:\")\n",
    "        print(f\"   {doc.page_content}\")\n",
    "        \n",
    "        # Complete metadata\n",
    "        print(f\"\\nğŸ“ Complete Metadata:\")\n",
    "        for key, value in metadata.items():\n",
    "            if value is not None and str(value) != 'nan':\n",
    "                clean_key = key.replace('_', ' ').title()\n",
    "                print(f\"   â€¢ {clean_key}: {value}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "else:\n",
    "    print(\"âŒ No results found. Try lowering the similarity threshold.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… End-to-end search demonstration complete!\")\n",
    "print(\"ğŸ’¡ The system successfully:\")\n",
    "print(\"   - Embedded the query using OpenAI\")\n",
    "print(\"   - Searched the vector database\")\n",
    "print(\"   - Applied similarity threshold filtering\")\n",
    "print(\"   - Ranked results appropriately\")\n",
    "print(\"   - Returned complete records with metadata\")\n",
    "print(\"   - Displayed results in both original and table formats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d6e13",
   "metadata": {},
   "source": [
    "## LLM Validation Pipeline\n",
    "\n",
    "Now we'll add an advanced LLM validation layer that takes the semantic search results and validates whether the diagnostic descriptions in the user's query actually match the maintenance issues found in the search results.\n",
    "\n",
    "This validation step uses a Language Model to:\n",
    "1. **Analyze the user's query** to extract the diagnostic intent\n",
    "2. **Compare search results** against the user's diagnostic description\n",
    "3. **Filter and rank results** based on diagnostic relevance\n",
    "4. **Provide explanations** for why results match or don't match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb5a41b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLM Validation Pipeline configured successfully!\n",
      "   - Model: gpt-4o\n",
      "   - Temperature: 0.1 (consistent validation)\n",
      "   - Validation focus: Diagnostic accuracy\n"
     ]
    }
   ],
   "source": [
    "# Set up LLM validation pipeline\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Get LLM model configuration from environment\n",
    "llm_model = os.getenv(\"LLM_MODEL\", \"gpt-4o\")  # Default fallback\n",
    "llm_temperature = float(os.getenv(\"TEMPERATURE\", \"0.1\"))  # Default for validation\n",
    "\n",
    "# Initialize the LLM for validation\n",
    "validation_llm = ChatOpenAI(\n",
    "    model=llm_model,\n",
    "    temperature=llm_temperature,  # Low temperature for consistent validation\n",
    "    openai_api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# Create the validation prompt template\n",
    "validation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are an expert automotive maintenance analyst. Your task is to validate if search results match the user's diagnostic query.\n",
    "\n",
    "USER QUERY: \"{user_query}\"\n",
    "\n",
    "SEARCH RESULTS TO VALIDATE:\n",
    "{search_results}\n",
    "\n",
    "For each search result, analyze:\n",
    "1. Does the maintenance comment describe the same or similar diagnostic issue as the user's query?\n",
    "2. How relevant is this result to the user's specific problem?\n",
    "3. What is the confidence level of this match?\n",
    "\n",
    "Provide your analysis in the following JSON format:\n",
    "{{\n",
    "    \"overall_assessment\": \"brief summary of how well results match the query\",\n",
    "    \"validated_results\": [\n",
    "        {{\n",
    "            \"result_index\": 1,\n",
    "            \"relevance_score\": 0.85,\n",
    "            \"is_diagnostic_match\": true,\n",
    "            \"explanation\": \"detailed explanation of why this result matches or doesn't match\",\n",
    "            \"key_similarities\": [\"list\", \"of\", \"key\", \"matching\", \"elements\"],\n",
    "            \"concerns\": [\"any\", \"concerns\", \"about\", \"the\", \"match\"]\n",
    "        }}\n",
    "    ],\n",
    "    \"recommendations\": \"suggestions for the user based on the validated results\"\n",
    "}}\n",
    "\n",
    "Be thorough but concise. Focus on diagnostic accuracy and practical relevance.\n",
    "\"\"\")\n",
    "\n",
    "# Create the validation chain\n",
    "validation_chain = validation_prompt | validation_llm | StrOutputParser()\n",
    "\n",
    "print(\"ğŸ§  LLM Validation Pipeline configured successfully!\")\n",
    "print(f\"   - Model: {llm_model}\")\n",
    "print(f\"   - Temperature: {llm_temperature} (consistent validation)\")\n",
    "print(f\"   - Validation focus: Diagnostic accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86f9d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM validation function created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Main LLM validation function\n",
    "def validate_search_results_with_llm(user_query: str, search_results: list, max_results_to_validate: int = 5):\n",
    "    \"\"\"\n",
    "    Validate search results using LLM to ensure diagnostic relevance\n",
    "    \n",
    "    Args:\n",
    "        user_query (str): The original user query\n",
    "        search_results (list): List of (document, score) tuples from semantic search\n",
    "        max_results_to_validate (int): Maximum number of results to send to LLM\n",
    "    \n",
    "    Returns:\n",
    "        dict: Validation results with filtered and ranked results\n",
    "    \"\"\"\n",
    "    if not search_results:\n",
    "        return {\n",
    "            \"validated_results\": [],\n",
    "            \"overall_assessment\": \"No search results to validate\",\n",
    "            \"recommendations\": \"Try a different query or lower the similarity threshold\"\n",
    "        }\n",
    "    \n",
    "    print(f\"ğŸ§  Validating {min(len(search_results), max_results_to_validate)} results with LLM...\")\n",
    "    \n",
    "    # Prepare search results for LLM analysis\n",
    "    results_for_validation = []\n",
    "    for i, (doc, score) in enumerate(search_results[:max_results_to_validate], 1):\n",
    "        result_data = {\n",
    "            \"index\": i,\n",
    "            \"similarity_score\": score,\n",
    "            \"comment\": doc.page_content,\n",
    "            \"metadata\": {\n",
    "                \"date\": doc.metadata.get('Completedate', 'No date'),\n",
    "                \"status\": doc.metadata.get('Orderstatus', 'Unknown'),\n",
    "                \"cost\": doc.metadata.get('Unitcst', 'No cost'),\n",
    "                \"compcode\": doc.metadata.get('Compcode', 'No code')\n",
    "            }\n",
    "        }\n",
    "        results_for_validation.append(result_data)\n",
    "    \n",
    "    # Format results for the LLM prompt\n",
    "    formatted_results = \"\"\n",
    "    for result in results_for_validation:\n",
    "        formatted_results += f\"\"\"\n",
    "Result {result['index']} (Similarity: {result['similarity_score']:.3f}):\n",
    "Comment: {result['comment'][:300]}{'...' if len(result['comment']) > 300 else ''}\n",
    "Date: {result['metadata']['date']}\n",
    "Status: {result['metadata']['status']}\n",
    "Cost: {result['metadata']['cost']}\n",
    "---\n",
    "\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Run the validation chain\n",
    "        validation_response = validation_chain.invoke({\n",
    "            \"user_query\": user_query,\n",
    "            \"search_results\": formatted_results\n",
    "        })\n",
    "        \n",
    "        # Try to parse the JSON response\n",
    "        try:\n",
    "            # Clean the response if it contains markdown code blocks\n",
    "            clean_response = validation_response.strip()\n",
    "            if clean_response.startswith('```json'):\n",
    "                clean_response = clean_response[7:]  # Remove ```json\n",
    "            if clean_response.endswith('```'):\n",
    "                clean_response = clean_response[:-3]  # Remove ```\n",
    "            clean_response = clean_response.strip()\n",
    "            \n",
    "            validation_data = json.loads(clean_response)\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback: extract key information from text response\n",
    "            print(\"âš ï¸ LLM response wasn't valid JSON, parsing as text...\")\n",
    "            validation_data = {\n",
    "                \"overall_assessment\": validation_response[:200] + \"...\" if len(validation_response) > 200 else validation_response,\n",
    "                \"validated_results\": [],\n",
    "                \"recommendations\": \"LLM validation completed but format needs review\"\n",
    "            }\n",
    "        \n",
    "        return validation_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ LLM validation failed: {e}\")\n",
    "        return {\n",
    "            \"overall_assessment\": f\"Validation failed: {str(e)}\",\n",
    "            \"validated_results\": [],\n",
    "            \"recommendations\": \"Validation system encountered an error\"\n",
    "        }\n",
    "\n",
    "print(\"âœ… LLM validation function created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "079aadfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Enhanced search function with LLM validation ready!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced search with LLM validation\n",
    "def semantic_search_with_llm_validation(\n",
    "    query: str, \n",
    "    k: int = 10, \n",
    "    similarity_threshold: float = SIMILARITY_THRESHOLD,\n",
    "    enable_llm_validation: bool = True,\n",
    "    max_validate: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete search pipeline with LLM validation\n",
    "    \n",
    "    Args:\n",
    "        query (str): Search query\n",
    "        k (int): Number of initial results to retrieve\n",
    "        similarity_threshold (float): Minimum similarity score\n",
    "        enable_llm_validation (bool): Whether to use LLM validation\n",
    "        max_validate (int): Maximum results to validate with LLM\n",
    "    \n",
    "    Returns:\n",
    "        dict: Complete search and validation results\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ Enhanced Search Pipeline Starting...\")\n",
    "    print(f\"   Query: '{query}'\")\n",
    "    print(f\"   LLM Validation: {'Enabled' if enable_llm_validation else 'Disabled'}\")\n",
    "    \n",
    "    # Step 1: Semantic search\n",
    "    print(f\"\\n1ï¸âƒ£ Running semantic search...\")\n",
    "    semantic_results = semantic_search_with_ranking(query, k, similarity_threshold)\n",
    "    \n",
    "    if not semantic_results:\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"semantic_results\": [],\n",
    "            \"validation_results\": None,\n",
    "            \"final_results\": [],\n",
    "            \"recommendations\": \"No semantic matches found. Try lowering similarity threshold or different keywords.\"\n",
    "        }\n",
    "    \n",
    "    # Step 2: LLM validation (if enabled)\n",
    "    validation_results = None\n",
    "    if enable_llm_validation:\n",
    "        print(f\"\\n2ï¸âƒ£ Running LLM validation...\")\n",
    "        validation_results = validate_search_results_with_llm(query, semantic_results, max_validate)\n",
    "    \n",
    "    # Step 3: Combine results\n",
    "    print(f\"\\n3ï¸âƒ£ Processing final results...\")\n",
    "    final_results = []\n",
    "    \n",
    "    if enable_llm_validation and validation_results and 'validated_results' in validation_results:\n",
    "        # Use LLM validation to filter and rank results\n",
    "        for validated_item in validation_results['validated_results']:\n",
    "            if validated_item.get('is_diagnostic_match', False) and validated_item.get('relevance_score', 0) > 0.5:\n",
    "                result_index = validated_item['result_index'] - 1  # Convert to 0-based index\n",
    "                if result_index < len(semantic_results):\n",
    "                    doc, original_score = semantic_results[result_index]\n",
    "                    final_results.append({\n",
    "                        'document': doc,\n",
    "                        'semantic_score': original_score,\n",
    "                        'llm_relevance': validated_item['relevance_score'],\n",
    "                        'explanation': validated_item['explanation'],\n",
    "                        'key_similarities': validated_item.get('key_similarities', []),\n",
    "                        'concerns': validated_item.get('concerns', [])\n",
    "                    })\n",
    "    else:\n",
    "        # Fall back to semantic results only\n",
    "        for doc, score in semantic_results:\n",
    "            final_results.append({\n",
    "                'document': doc,\n",
    "                'semantic_score': score,\n",
    "                'llm_relevance': None,\n",
    "                'explanation': 'LLM validation not performed',\n",
    "                'key_similarities': [],\n",
    "                'concerns': []\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"semantic_results\": semantic_results,\n",
    "        \"validation_results\": validation_results,\n",
    "        \"final_results\": final_results,\n",
    "        \"total_semantic_matches\": len(semantic_results),\n",
    "        \"total_validated_matches\": len(final_results),\n",
    "        \"recommendations\": validation_results.get('recommendations', 'Search completed successfully') if validation_results else \"Semantic search completed\"\n",
    "    }\n",
    "\n",
    "print(\"ğŸ¯ Enhanced search function with LLM validation ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc42ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Enhanced results display function ready!\n"
     ]
    }
   ],
   "source": [
    "# Display function for enhanced validation results\n",
    "def display_validated_results(search_results: dict):\n",
    "    \"\"\"Display enhanced search results with LLM validation\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Enhanced Search Results for: '{search_results['query']}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show summary\n",
    "    semantic_count = search_results['total_semantic_matches']\n",
    "    validated_count = search_results['total_validated_matches']\n",
    "    \n",
    "    print(f\"ğŸ“Š Summary:\")\n",
    "    print(f\"   â€¢ Semantic matches found: {semantic_count}\")\n",
    "    print(f\"   â€¢ LLM validated matches: {validated_count}\")\n",
    "    print(f\"   â€¢ Validation enabled: {'Yes' if search_results['validation_results'] else 'No'}\")\n",
    "    \n",
    "    # Show overall assessment if available\n",
    "    if search_results['validation_results'] and 'overall_assessment' in search_results['validation_results']:\n",
    "        assessment = search_results['validation_results']['overall_assessment']\n",
    "        print(f\"   â€¢ LLM Assessment: {assessment}\")\n",
    "    \n",
    "    # Display validated results\n",
    "    final_results = search_results['final_results']\n",
    "    \n",
    "    if not final_results:\n",
    "        print(f\"\\nâŒ No validated results found\")\n",
    "        print(f\"ğŸ’¡ {search_results['recommendations']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nğŸ† Validated Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(final_results, 1):\n",
    "        doc = result['document']\n",
    "        semantic_score = result['semantic_score']\n",
    "        llm_relevance = result['llm_relevance']\n",
    "        explanation = result['explanation']\n",
    "        \n",
    "        print(f\"\\nğŸ“„ Result #{i}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Scores\n",
    "        scores_info = f\"Semantic: {semantic_score:.3f}\"\n",
    "        if llm_relevance is not None:\n",
    "            scores_info += f\" | LLM Relevance: {llm_relevance:.3f}\"\n",
    "        print(f\"ğŸ¯ Scores: {scores_info}\")\n",
    "        \n",
    "        # Comment\n",
    "        comment = doc.page_content\n",
    "        print(f\"ğŸ’¬ Comment: {comment[:200]}{'...' if len(comment) > 200 else ''}\")\n",
    "        \n",
    "        # LLM explanation\n",
    "        if explanation and explanation != 'LLM validation not performed':\n",
    "            print(f\"ğŸ§  LLM Analysis: {explanation[:300]}{'...' if len(explanation) > 300 else ''}\")\n",
    "        \n",
    "        # Key similarities\n",
    "        if result['key_similarities']:\n",
    "            similarities = ', '.join(result['key_similarities'][:3])\n",
    "            print(f\"ğŸ”— Key Matches: {similarities}\")\n",
    "        \n",
    "        # Concerns\n",
    "        if result['concerns']:\n",
    "            concerns = ', '.join(result['concerns'][:2])\n",
    "            print(f\"âš ï¸ Concerns: {concerns}\")\n",
    "        \n",
    "        # Metadata\n",
    "        metadata = doc.metadata\n",
    "        print(f\"ğŸ“ Metadata:\")\n",
    "        if 'Completedate' in metadata and metadata['Completedate']:\n",
    "            print(f\"   â€¢ Date: {metadata['Completedate']}\")\n",
    "        if 'Orderstatus' in metadata and metadata['Orderstatus']:\n",
    "            print(f\"   â€¢ Status: {metadata['Orderstatus']}\")\n",
    "        if 'Unitcst' in metadata and metadata['Unitcst']:\n",
    "            print(f\"   â€¢ Cost: ${metadata['Unitcst']}\")\n",
    "    \n",
    "    # Show recommendations\n",
    "    print(f\"\\nğŸ’¡ Recommendations: {search_results['recommendations']}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"ğŸ“‹ Enhanced results display function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f038d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Enhanced table display function created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Enhanced table display function for LLM validation results\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def display_validated_results_table(search_results: dict):\n",
    "    \"\"\"Display enhanced search results with LLM validation in a structured table format\"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Enhanced Search Results for: '{search_results['query']}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show summary\n",
    "    semantic_count = search_results['total_semantic_matches']\n",
    "    validated_count = search_results['total_validated_matches']\n",
    "    \n",
    "    print(f\"ğŸ“Š Summary:\")\n",
    "    print(f\"   â€¢ Semantic matches found: {semantic_count}\")\n",
    "    print(f\"   â€¢ LLM validated matches: {validated_count}\")\n",
    "    print(f\"   â€¢ Validation enabled: {'Yes' if search_results['validation_results'] else 'No'}\")\n",
    "    \n",
    "    # Show overall assessment if available\n",
    "    if search_results['validation_results'] and 'overall_assessment' in search_results['validation_results']:\n",
    "        assessment = search_results['validation_results']['overall_assessment']\n",
    "        print(f\"   â€¢ LLM Assessment: {assessment}\")\n",
    "    \n",
    "    # Display validated results\n",
    "    final_results = search_results['final_results']\n",
    "    \n",
    "    if not final_results:\n",
    "        print(f\"\\nâŒ No validated results found\")\n",
    "        print(f\"ğŸ’¡ {search_results['recommendations']}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nğŸ† Validated Results Table:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Prepare data for table\n",
    "    table_data = []\n",
    "    \n",
    "    for i, result in enumerate(final_results, 1):\n",
    "        doc = result['document']\n",
    "        semantic_score = result['semantic_score']\n",
    "        llm_relevance = result['llm_relevance']\n",
    "        explanation = result['explanation']\n",
    "        metadata = doc.metadata\n",
    "        \n",
    "        # Create a comprehensive row with all available metadata\n",
    "        row = {\n",
    "            'Result #': i,\n",
    "            'Semantic Score': f\"{semantic_score:.3f}\",\n",
    "            'LLM Relevance': f\"{llm_relevance:.3f}\" if llm_relevance is not None else \"N/A\",\n",
    "            'Comment Preview': doc.page_content[:100] + \"...\" if len(doc.page_content) > 100 else doc.page_content,\n",
    "            'LLM Explanation': explanation[:150] + \"...\" if len(explanation) > 150 else explanation,\n",
    "            'Key Similarities': ', '.join(result['key_similarities'][:3]) if result['key_similarities'] else \"None\",\n",
    "            'Concerns': ', '.join(result['concerns'][:2]) if result['concerns'] else \"None\"\n",
    "        }\n",
    "        \n",
    "        # Add all metadata fields dynamically\n",
    "        for key, value in metadata.items():\n",
    "            if value is not None and str(value) != 'nan':\n",
    "                # Clean up key names for better display\n",
    "                clean_key = key.replace('_', ' ').title()\n",
    "                if isinstance(value, str) and len(value) > 50:\n",
    "                    row[clean_key] = value[:50] + \"...\"\n",
    "                else:\n",
    "                    row[clean_key] = str(value)\n",
    "        \n",
    "        table_data.append(row)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_results = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Display the table\n",
    "    display(df_results)\n",
    "    \n",
    "    # Also show detailed view for each result\n",
    "    print(f\"\\nğŸ“‹ Detailed Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, result in enumerate(final_results, 1):\n",
    "        doc = result['document']\n",
    "        semantic_score = result['semantic_score']\n",
    "        llm_relevance = result['llm_relevance']\n",
    "        explanation = result['explanation']\n",
    "        metadata = doc.metadata\n",
    "        \n",
    "        print(f\"\\nğŸ“„ Result #{i} Details:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Scores section\n",
    "        print(f\"ğŸ¯ Scores:\")\n",
    "        print(f\"   â€¢ Semantic Score: {semantic_score:.3f}\")\n",
    "        if llm_relevance is not None:\n",
    "            print(f\"   â€¢ LLM Relevance: {llm_relevance:.3f}\")\n",
    "        \n",
    "        # Full comment\n",
    "        print(f\"\\nğŸ’¬ Full Comment:\")\n",
    "        print(f\"   {doc.page_content}\")\n",
    "        \n",
    "        # LLM Analysis\n",
    "        if explanation and explanation != 'LLM validation not performed':\n",
    "            print(f\"\\nğŸ§  LLM Analysis:\")\n",
    "            print(f\"   {explanation}\")\n",
    "        \n",
    "        # Key similarities and concerns\n",
    "        if result['key_similarities']:\n",
    "            print(f\"\\nğŸ”— Key Similarities: {', '.join(result['key_similarities'])}\")\n",
    "        if result['concerns']:\n",
    "            print(f\"\\nâš ï¸ Concerns: {', '.join(result['concerns'])}\")\n",
    "        \n",
    "        # Complete metadata\n",
    "        print(f\"\\nğŸ“ Complete Metadata:\")\n",
    "        for key, value in metadata.items():\n",
    "            if value is not None and str(value) != 'nan':\n",
    "                clean_key = key.replace('_', ' ').title()\n",
    "                print(f\"   â€¢ {clean_key}: {value}\")\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Show recommendations\n",
    "    print(f\"\\nğŸ’¡ Recommendations: {search_results['recommendations']}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print(\"ğŸ“Š Enhanced table display function created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3a829",
   "metadata": {},
   "source": [
    "### ğŸ“Š Enhanced Table Display for LLM Validation Results\n",
    "\n",
    "The new **structured table display** function (`display_validated_results_table()`) provides a comprehensive view of LLM validation results in multiple formats:\n",
    "\n",
    "#### ğŸ—ï¸ **Table Structure**\n",
    "\n",
    "1. **ğŸ“Š Pandas DataFrame**: Comprehensive overview table with all key information\n",
    "   - Semantic and LLM scores\n",
    "   - Comment previews\n",
    "   - LLM explanations\n",
    "   - Key similarities and concerns\n",
    "   - All metadata fields from the Excel data\n",
    "\n",
    "2. **ğŸ“‹ Detailed Individual Results**: Complete information for each result\n",
    "   - Full comment text (not truncated)\n",
    "   - Complete LLM analysis\n",
    "   - All metadata fields with clean formatting\n",
    "   - Scores and validation details\n",
    "\n",
    "#### ğŸ” **Key Features**\n",
    "\n",
    "- **Dynamic Metadata**: Automatically includes all available Excel columns\n",
    "- **Clean Formatting**: Removes underscores, handles long text gracefully\n",
    "- **Export Ready**: Pandas DataFrame can be easily exported to CSV/Excel\n",
    "- **Complete Information**: No data is lost in the display\n",
    "- **Visual Hierarchy**: Clear separation between overview and details\n",
    "\n",
    "#### ğŸ’¡ **When to Use**\n",
    "\n",
    "- **Table Format**: When you need a quick overview and want to analyze multiple results\n",
    "- **Original Format**: When you prefer a narrative, easy-to-read display\n",
    "- **Both**: For comprehensive analysis and documentation\n",
    "\n",
    "This dual approach gives you the best of both worlds: structured data analysis and human-readable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bed5d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Demonstration: Enhanced Table Display\n",
      "==================================================\n",
      "ğŸ” Demo Query: 'seatbelt buckle mechanism failure'\n",
      "ğŸ“‹ This will show results in both table and detailed formats\n",
      "ğŸš€ Enhanced Search Pipeline Starting...\n",
      "   Query: 'seatbelt buckle mechanism failure'\n",
      "   LLM Validation: Enabled\n",
      "\n",
      "1ï¸âƒ£ Running semantic search...\n",
      "ğŸ” Searching for: 'seatbelt buckle mechanism failure'\n",
      "ğŸ“Š Similarity threshold: 0.49999999999999994\n",
      "ğŸ“… Results will be ranked by date (newest first)\n",
      "âœ… Found 3 results above threshold 0.49999999999999994\n",
      "\n",
      "2ï¸âƒ£ Running LLM validation...\n",
      "ğŸ§  Validating 3 results with LLM...\n",
      "âœ… Found 3 results above threshold 0.49999999999999994\n",
      "\n",
      "2ï¸âƒ£ Running LLM validation...\n",
      "ğŸ§  Validating 3 results with LLM...\n",
      "\n",
      "3ï¸âƒ£ Processing final results...\n",
      "\n",
      "âœ… Found 3 validated results\n",
      "ğŸ“Š Displaying in structured table format...\n",
      "\n",
      "ğŸ¯ Enhanced Search Results for: 'seatbelt buckle mechanism failure'\n",
      "================================================================================\n",
      "ğŸ“Š Summary:\n",
      "   â€¢ Semantic matches found: 3\n",
      "   â€¢ LLM validated matches: 3\n",
      "   â€¢ Validation enabled: Yes\n",
      "   â€¢ LLM Assessment: All search results describe a seatbelt buckle replacement due to a broken buckle, which aligns well with the user's query about seatbelt buckle mechanism failure.\n",
      "\n",
      "ğŸ† Validated Results Table:\n",
      "================================================================================\n",
      "\n",
      "3ï¸âƒ£ Processing final results...\n",
      "\n",
      "âœ… Found 3 validated results\n",
      "ğŸ“Š Displaying in structured table format...\n",
      "\n",
      "ğŸ¯ Enhanced Search Results for: 'seatbelt buckle mechanism failure'\n",
      "================================================================================\n",
      "ğŸ“Š Summary:\n",
      "   â€¢ Semantic matches found: 3\n",
      "   â€¢ LLM validated matches: 3\n",
      "   â€¢ Validation enabled: Yes\n",
      "   â€¢ LLM Assessment: All search results describe a seatbelt buckle replacement due to a broken buckle, which aligns well with the user's query about seatbelt buckle mechanism failure.\n",
      "\n",
      "ğŸ† Validated Results Table:\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Result #",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Semantic Score",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LLM Relevance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comment Preview",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "LLM Explanation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Key Similarities",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Concerns",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Completedate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Unitcst",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Hours",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Comment Length",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qty",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Orderid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Linetotal",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Compcode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Row Index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Orderstatus",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Linetype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Compcodedescrip",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0428e2c9-9276-4a3b-8e49-ad768a4ba2fe",
       "rows": [
        [
         "0",
         "1",
         "0.732",
         "0.850",
         "<Correction>Replaced seatbelt buckle</Correction><Notes></Notes><Cause>Seatbelt buckle broke</Cause>...",
         "The result describes a seatbelt buckle replacement due to a broken buckle, which directly relates to a mechanism failure.",
         "seatbelt buckle, broke, mechanism failure",
         "None",
         "2025-04-10T07:32:00",
         "74.0",
         "0.55",
         "173",
         "0",
         "12729042",
         "40.7",
         "002-011-003 ",
         "67",
         "REPAIR      ",
         "LABOR       ",
         "Seat Belt & Retainer Assembly                     ..."
        ],
        [
         "1",
         "2",
         "0.732",
         "0.850",
         "<Correction>Replaced seatbelt buckle</Correction><Notes></Notes><Cause>Seatbelt buckle broke</Cause>...",
         "This result also involves replacing a seatbelt buckle because it broke, indicating a mechanism failure.",
         "seatbelt buckle, broke, mechanism failure",
         "None",
         "2025-04-17T11:42:00",
         "109.3225",
         "0.0",
         "173",
         "1",
         "12795355",
         "109.32",
         "002-011-003 ",
         "99",
         "REPAIR      ",
         "PART        ",
         "Seat Belt & Retainer Assembly                     ..."
        ],
        [
         "2",
         "3",
         "0.732",
         "0.850",
         "<Correction>Replaced seatbelt buckle</Correction><Notes></Notes><Cause>Seatbelt buckle broke</Cause>...",
         "The replacement of a broken seatbelt buckle suggests a mechanism failure, matching the user's query.",
         "seatbelt buckle, broke, mechanism failure",
         "None",
         "2025-05-19T09:38:00",
         "109.5494",
         "0.0",
         "173",
         "1",
         "12971816",
         "109.55",
         "002-011-003 ",
         "157",
         "REPAIR      ",
         "PART        ",
         "Seat Belt & Retainer Assembly                     ..."
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result #</th>\n",
       "      <th>Semantic Score</th>\n",
       "      <th>LLM Relevance</th>\n",
       "      <th>Comment Preview</th>\n",
       "      <th>LLM Explanation</th>\n",
       "      <th>Key Similarities</th>\n",
       "      <th>Concerns</th>\n",
       "      <th>Completedate</th>\n",
       "      <th>Unitcst</th>\n",
       "      <th>Hours</th>\n",
       "      <th>Comment Length</th>\n",
       "      <th>Qty</th>\n",
       "      <th>Orderid</th>\n",
       "      <th>Linetotal</th>\n",
       "      <th>Compcode</th>\n",
       "      <th>Row Index</th>\n",
       "      <th>Orderstatus</th>\n",
       "      <th>Linetype</th>\n",
       "      <th>Compcodedescrip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.850</td>\n",
       "      <td>&lt;Correction&gt;Replaced seatbelt buckle&lt;/Correcti...</td>\n",
       "      <td>The result describes a seatbelt buckle replace...</td>\n",
       "      <td>seatbelt buckle, broke, mechanism failure</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-10T07:32:00</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>12729042</td>\n",
       "      <td>40.7</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>67</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>LABOR</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.850</td>\n",
       "      <td>&lt;Correction&gt;Replaced seatbelt buckle&lt;/Correcti...</td>\n",
       "      <td>This result also involves replacing a seatbelt...</td>\n",
       "      <td>seatbelt buckle, broke, mechanism failure</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-17T11:42:00</td>\n",
       "      <td>109.3225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>12795355</td>\n",
       "      <td>109.32</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>99</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>PART</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.850</td>\n",
       "      <td>&lt;Correction&gt;Replaced seatbelt buckle&lt;/Correcti...</td>\n",
       "      <td>The replacement of a broken seatbelt buckle su...</td>\n",
       "      <td>seatbelt buckle, broke, mechanism failure</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-05-19T09:38:00</td>\n",
       "      <td>109.5494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>12971816</td>\n",
       "      <td>109.55</td>\n",
       "      <td>002-011-003</td>\n",
       "      <td>157</td>\n",
       "      <td>REPAIR</td>\n",
       "      <td>PART</td>\n",
       "      <td>Seat Belt &amp; Retainer Assembly                 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Result # Semantic Score LLM Relevance                                    Comment Preview                                    LLM Explanation                           Key Similarities Concerns         Completedate   Unitcst Hours Comment Length Qty   Orderid Linetotal      Compcode Row Index   Orderstatus      Linetype                                    Compcodedescrip\n",
       "0         1          0.732         0.850  <Correction>Replaced seatbelt buckle</Correcti...  The result describes a seatbelt buckle replace...  seatbelt buckle, broke, mechanism failure     None  2025-04-10T07:32:00      74.0  0.55            173   0  12729042      40.7  002-011-003         67  REPAIR        LABOR         Seat Belt & Retainer Assembly                 ...\n",
       "1         2          0.732         0.850  <Correction>Replaced seatbelt buckle</Correcti...  This result also involves replacing a seatbelt...  seatbelt buckle, broke, mechanism failure     None  2025-04-17T11:42:00  109.3225   0.0            173   1  12795355    109.32  002-011-003         99  REPAIR        PART          Seat Belt & Retainer Assembly                 ...\n",
       "2         3          0.732         0.850  <Correction>Replaced seatbelt buckle</Correcti...  The replacement of a broken seatbelt buckle su...  seatbelt buckle, broke, mechanism failure     None  2025-05-19T09:38:00  109.5494   0.0            173   1  12971816    109.55  002-011-003        157  REPAIR        PART          Seat Belt & Retainer Assembly                 ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Detailed Results:\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ Result #1 Details:\n",
      "--------------------------------------------------\n",
      "ğŸ¯ Scores:\n",
      "   â€¢ Semantic Score: 0.732\n",
      "   â€¢ LLM Relevance: 0.850\n",
      "\n",
      "ğŸ’¬ Full Comment:\n",
      "   <Correction>Replaced seatbelt buckle</Correction><Notes></Notes><Cause>Seatbelt buckle broke</Cause><Complaint>Mechanic inspection</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "ğŸ§  LLM Analysis:\n",
      "   The result describes a seatbelt buckle replacement due to a broken buckle, which directly relates to a mechanism failure.\n",
      "\n",
      "ğŸ”— Key Similarities: seatbelt buckle, broke, mechanism failure\n",
      "\n",
      "âš ï¸ Concerns: None\n",
      "\n",
      "ğŸ“ Complete Metadata:\n",
      "   â€¢ Completedate: 2025-04-10T07:32:00\n",
      "   â€¢ Unitcst: 74.0\n",
      "   â€¢ Hours: 0.55\n",
      "   â€¢ Comment Length: 173\n",
      "   â€¢ Qty: 0\n",
      "   â€¢ Orderid: 12729042\n",
      "   â€¢ Linetotal: 40.7\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Row Index: 67\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Linetype: LABOR       \n",
      "   â€¢ Compcodedescrip: Seat Belt & Retainer Assembly                               \n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“„ Result #2 Details:\n",
      "--------------------------------------------------\n",
      "ğŸ¯ Scores:\n",
      "   â€¢ Semantic Score: 0.732\n",
      "   â€¢ LLM Relevance: 0.850\n",
      "\n",
      "ğŸ’¬ Full Comment:\n",
      "   <Correction>Replaced seatbelt buckle</Correction><Notes></Notes><Cause>Seatbelt buckle broke</Cause><Complaint>Mechanic inspection</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "ğŸ§  LLM Analysis:\n",
      "   This result also involves replacing a seatbelt buckle because it broke, indicating a mechanism failure.\n",
      "\n",
      "ğŸ”— Key Similarities: seatbelt buckle, broke, mechanism failure\n",
      "\n",
      "âš ï¸ Concerns: None\n",
      "\n",
      "ğŸ“ Complete Metadata:\n",
      "   â€¢ Row Index: 99\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Orderid: 12795355\n",
      "   â€¢ Unitcst: 109.3225\n",
      "   â€¢ Hours: 0.0\n",
      "   â€¢ Comment Length: 173\n",
      "   â€¢ Completedate: 2025-04-17T11:42:00\n",
      "   â€¢ Linetype: PART        \n",
      "   â€¢ Compcodedescrip: Seat Belt & Retainer Assembly                               \n",
      "   â€¢ Qty: 1\n",
      "   â€¢ Linetotal: 109.32\n",
      "   â€¢ Compcode: 002-011-003 \n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ“„ Result #3 Details:\n",
      "--------------------------------------------------\n",
      "ğŸ¯ Scores:\n",
      "   â€¢ Semantic Score: 0.732\n",
      "   â€¢ LLM Relevance: 0.850\n",
      "\n",
      "ğŸ’¬ Full Comment:\n",
      "   <Correction>Replaced seatbelt buckle</Correction><Notes></Notes><Cause>Seatbelt buckle broke</Cause><Complaint>Mechanic inspection</Complaint><CauseOfRepair></CauseOfRepair>\n",
      "\n",
      "ğŸ§  LLM Analysis:\n",
      "   The replacement of a broken seatbelt buckle suggests a mechanism failure, matching the user's query.\n",
      "\n",
      "ğŸ”— Key Similarities: seatbelt buckle, broke, mechanism failure\n",
      "\n",
      "âš ï¸ Concerns: None\n",
      "\n",
      "ğŸ“ Complete Metadata:\n",
      "   â€¢ Orderid: 12971816\n",
      "   â€¢ Qty: 1\n",
      "   â€¢ Compcodedescrip: Seat Belt & Retainer Assembly                               \n",
      "   â€¢ Comment Length: 173\n",
      "   â€¢ Row Index: 157\n",
      "   â€¢ Linetype: PART        \n",
      "   â€¢ Completedate: 2025-05-19T09:38:00\n",
      "   â€¢ Hours: 0.0\n",
      "   â€¢ Orderstatus: REPAIR      \n",
      "   â€¢ Compcode: 002-011-003 \n",
      "   â€¢ Linetotal: 109.55\n",
      "   â€¢ Unitcst: 109.5494\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ’¡ Recommendations: The user should consider these results as relevant to their query about seatbelt buckle mechanism failure. If the issue persists, further inspection of the seatbelt system may be necessary to ensure no other components are affected.\n",
      "================================================================================\n",
      "\n",
      "==================================================\n",
      "ğŸ’¡ The table format provides:\n",
      "   â€¢ ğŸ“Š Comprehensive overview in pandas DataFrame\n",
      "   â€¢ ğŸ” Detailed view with complete metadata\n",
      "   â€¢ ğŸ“‹ All available fields from the Excel data\n",
      "   â€¢ ğŸ§  LLM analysis and explanations\n",
      "   â€¢ âš¡ Easy to export or further analyze\n"
     ]
    }
   ],
   "source": [
    "# Demonstration: Structured Table Display for LLM Validation Results\n",
    "print(\"ğŸ“Š Demonstration: Enhanced Table Display\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Example query for demonstration\n",
    "demo_query = \"seatbelt buckle mechanism failure\"\n",
    "print(f\"ğŸ” Demo Query: '{demo_query}'\")\n",
    "print(f\"ğŸ“‹ This will show results in both table and detailed formats\")\n",
    "\n",
    "# Use a lower threshold for demonstration to ensure we get results\n",
    "demo_threshold = SIMILARITY_THRESHOLD - 0.2\n",
    "\n",
    "try:\n",
    "    # Run enhanced search with LLM validation\n",
    "    demo_results = semantic_search_with_llm_validation(\n",
    "        query=demo_query,\n",
    "        k=3,  # Get 3 results for demonstration\n",
    "        similarity_threshold=demo_threshold,\n",
    "        enable_llm_validation=True,\n",
    "        max_validate=3\n",
    "    )\n",
    "    \n",
    "    if demo_results['final_results']:\n",
    "        print(f\"\\nâœ… Found {len(demo_results['final_results'])} validated results\")\n",
    "        print(\"ğŸ“Š Displaying in structured table format...\")\n",
    "        \n",
    "        # Display using the new table format\n",
    "        display_validated_results_table(demo_results)\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ No validated results found for demonstration\")\n",
    "        print(f\"   Trying with original display format...\")\n",
    "        \n",
    "        # Fallback to original display\n",
    "        display_validated_results(demo_results)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Demo failed: {e}\")\n",
    "    print(\"ğŸ’¡ This might be due to API limits or connectivity issues\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ’¡ The table format provides:\")\n",
    "print(\"   â€¢ ğŸ“Š Comprehensive overview in pandas DataFrame\")\n",
    "print(\"   â€¢ ğŸ” Detailed view with complete metadata\")\n",
    "print(\"   â€¢ ğŸ“‹ All available fields from the Excel data\")\n",
    "print(\"   â€¢ ğŸ§  LLM analysis and explanations\")\n",
    "print(\"   â€¢ âš¡ Easy to export or further analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9765e9e",
   "metadata": {},
   "source": [
    "## âœ… LLM Validation System Complete!\n",
    "\n",
    "### ğŸ¯ **What We've Built**\n",
    "\n",
    "The enhanced semantic search system now includes a sophisticated **LLM Validation Pipeline** that adds intelligence to the search results:\n",
    "\n",
    "### ğŸ”„ **Two-Stage Process**\n",
    "\n",
    "1. **Stage 1 - Semantic Search**: \n",
    "   - Uses OpenAI embeddings to find semantically similar maintenance comments\n",
    "   - Applies similarity thresholds and date-based ranking\n",
    "   - Returns initial candidates based on vector similarity\n",
    "\n",
    "2. **Stage 2 - LLM Validation**:\n",
    "   - Uses **GPT-4o** (configured via `.env` file) to analyze search results\n",
    "   - Validates if the diagnostic descriptions actually match the user's query\n",
    "   - Provides detailed explanations and confidence scores\n",
    "   - Filters out false positives from semantic search\n",
    "\n",
    "### ğŸ§  **LLM Validation Features**\n",
    "\n",
    "- **Diagnostic Accuracy**: Validates that maintenance issues truly match the user's problem\n",
    "- **Relevance Scoring**: Provides confidence scores (0.0-1.0) for each result\n",
    "- **Detailed Explanations**: Explains why results match or don't match\n",
    "- **Key Similarities**: Identifies specific matching elements\n",
    "- **Concern Flagging**: Highlights potential issues with matches\n",
    "- **Recommendations**: Provides actionable advice based on validated results\n",
    "\n",
    "### âš™ï¸ **Configuration**\n",
    "\n",
    "- **Model**: Reads from `.env` file (`LLM_MODEL=gpt-4o`)\n",
    "- **Temperature**: Optimized for consistent validation (0.1)\n",
    "- **Fallback**: Graceful degradation if LLM validation fails\n",
    "- **Customizable**: Can be enabled/disabled per search\n",
    "\n",
    "### ğŸš€ **Usage Examples**\n",
    "\n",
    "```python\n",
    "# With LLM validation (recommended)\n",
    "results = semantic_search_with_llm_validation(\n",
    "    query=\"broken seatbelt buckle won't latch\",\n",
    "    k=5,\n",
    "    similarity_threshold=0.6,\n",
    "    enable_llm_validation=True\n",
    ")\n",
    "\n",
    "# Display enhanced results\n",
    "display_validated_results(results)\n",
    "\n",
    "# Without LLM validation (faster, semantic only)\n",
    "results = semantic_search_with_llm_validation(\n",
    "    query=\"broken seatbelt buckle won't latch\", \n",
    "    enable_llm_validation=False\n",
    ")\n",
    "```\n",
    "\n",
    "This creates a **production-ready intelligent search system** that combines the speed of vector search with the accuracy of LLM validation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
