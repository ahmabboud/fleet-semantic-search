# Semantic Search Demo with Excel Data

A comprehensive demonstration of building an intelligent search system th3. **Intelligent Search**
- **Semantic understanding** beyond keyword matching
- **Configurable similarity thresholds** (0.0 to 1.0)
- **Date-based ranking** (newest results first)
- **Complete record retrieval** with all metadata

### 4. **ðŸ§  LLM Validation Pipeline** (NEW!)
- **Two-stage validation** for enhanced accuracy
- **Diagnostic relevance check### Understanding the Results

### Enhanced Result Format
Each enhanced search result includes:
- **Semantic Score**: Vector similarity score (0.0-1.0)
- **LLM Relevance**: Validation confidence score (0.0-1.0)
- **Full Comment**: The complete maintenance comment
- **LLM Explanation**: Detailed reasoning for the match
- **Key Similarities**: Specific matching elements identified by LLM
- **Concerns**: Potential limitations or issues flagged
- **Metadata**: Date, vehicle ID, status, costs, etc.
- **Ranking**: Sorted by LLM relevance, then by date

### Interpreting Enhanced Scores
- **LLM Relevance 0.9+**: Exceptional diagnostic match
- **LLM Relevance 0.7-0.9**: Strong diagnostic relevance  
- **LLM Relevance 0.5-0.7**: Moderate relevance, review explanation
- **LLM Relevance < 0.5**: Filtered out as potential false positive
- **No LLM Score**: Validation was skipped or faileding GPT-4o
- **Detailed explanations** for each match
- **Confidence scoring** with reasoning
- **False positive filtering** to improve precision

### 5. User-Friendly Interface
- **Interactive search function** for real-time queries
- **Enhanced result display** with LLM analysis
- **Customizable search parameters**ands the meaning behind your queries, not just keywords. This notebook shows how to transform Excel data into a searchable vector database using modern AI techniques.

## ðŸŽ¯ What This Demo Does

This notebook demonstrates how to:
1. **Load Excel data** and analyze its structure
2. **Create a vector database** that understands semantic meaning
3. **Implement intelligent search** that finds relevant content even without exact keyword matches
4. **Rank results by date** with configurable similarity thresholds
5. **Preserve complete records** while searching through specific text fields

## ðŸ“Š Use Case: Fleet Maintenance Comments

The demo uses real-world fleet maintenance data (`Lm_orders_seatbelt_v2.xlsx`) containing:
- **237 maintenance records** with detailed comments
- **Vehicle information** and timestamps
- **Repair descriptions** in natural language
- **Status tracking** and cost information

### Example Searches
- *"seat belt buckle broken"* â†’ Finds records about buckle malfunctions
- *"safety equipment malfunction"* â†’ Discovers safety-related issues
- *"urgent repair needed"* â†’ Locates high-priority maintenance items

## ðŸ§  How Semantic Search Works

### Traditional Keyword Search vs. Semantic Search

| Traditional Search | Semantic Search | LLM-Enhanced Search |
|-------------------|-----------------|---------------------|
| Looks for exact word matches | Understands meaning and context | Validates diagnostic accuracy |
| "broken buckle" only finds "broken" AND "buckle" | "faulty latch" can find "broken buckle" | Confirms maintenance relevance |
| Limited to exact terminology | Works with synonyms and related concepts | Filters false positives |
| Misses relevant results | Finds conceptually similar content | Explains why results match |

### The Enhanced Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Enhanced Semantic Search Pipeline               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Text Embeddings         â”‚ â”‚     Vector Database        â”‚
â”‚   (OpenAI's AI Model)       â”‚ â”‚      (ChromaDB)           â”‚
â”‚                             â”‚ â”‚                            â”‚
â”‚ â€¢ Converts text to numbers  â”‚ â”‚ â€¢ Stores vector data       â”‚
â”‚ â€¢ Captures semantic meaning â”‚ â”‚ â€¢ Enables fast similarity â”‚
â”‚ â€¢ 1536-dimensional vectors  â”‚ â”‚   searches                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                          â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    LangChain Pipeline          â”‚
          â”‚                                â”‚
          â”‚ â€¢ Query processing             â”‚
          â”‚ â€¢ Similarity matching          â”‚
          â”‚ â€¢ Date-based ranking           â”‚
          â”‚ â€¢ Threshold filtering          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   ðŸ§  LLM Validation Layer      â”‚
          â”‚        (GPT-4o)               â”‚
          â”‚                                â”‚
          â”‚ â€¢ Diagnostic accuracy check    â”‚
          â”‚ â€¢ Relevance validation        â”‚
          â”‚ â€¢ Detailed explanations       â”‚
          â”‚ â€¢ Confidence scoring          â”‚
          â”‚ â€¢ False positive filtering    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Getting Started

### Prerequisites

1. **Python Environment** (3.8+)
2. **OpenAI API Key** (for embeddings)
3. **Required Libraries** (see `requirements.txt`)

### Setup Instructions

1. **Install Dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure OpenAI API**
   Create a `.env` file:
   ```
   OPENAI_API_KEY=your_api_key_here
   EMBEDDING_MODEL=text-embedding-3-small
   LLM_MODEL=gpt-4o
   TEMPERATURE=0.1
   ```

3. **Run the Notebook**
   Execute cells in order to:
   - Load and analyze the Excel data
   - Create the vector database
   - Set up the search pipeline
   - Test with example queries

## ðŸ“ File Structure

```
SampleData/
â”œâ”€â”€ Demo sementic search.ipynb    # Main notebook
â”œâ”€â”€ Lm_orders_seatbelt_v2.xlsx   # Source Excel data
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .env                         # API configuration
â”œâ”€â”€ chroma_db/                   # Vector database (auto-created)
â””â”€â”€ README.md                    # This file
```

## ðŸ’¡ Key Features

### 1. Smart Data Processing
- **Automatic filtering** of empty or short comments
- **Metadata preservation** for all Excel columns
- **Batch processing** for efficient database loading

### 2. Intelligent Search
- **Semantic understanding** beyond keyword matching
- **Configurable similarity thresholds** (0.0 to 1.0)
- **Date-based ranking** (newest results first)
- **Complete record retrieval** with all metadata

### 3. User-Friendly Interface
- **Interactive search function** for real-time queries
- **Detailed result display** with similarity scores
- **Customizable search parameters**

## ðŸ”§ Usage Examples

### Basic Semantic Search
```python
# Search with default settings
results = semantic_search_with_ranking(
    query="seat belt issues",
    k=5,
    similarity_threshold=0.7
)
```

### Enhanced Search with LLM Validation
```python
# Complete search with LLM validation (RECOMMENDED)
results = semantic_search_with_llm_validation(
    query="seatbelt buckle is broken and won't latch properly",
    k=5,
    similarity_threshold=0.6,
    enable_llm_validation=True,
    max_validate=3
)

# Display enhanced results with explanations
display_validated_results(results)
```

### Advanced Search Configuration
```python
# Custom threshold and result count
results = semantic_search_with_ranking(
    query="safety equipment malfunction",
    k=10,
    similarity_threshold=0.6
)
```

### Interactive Mode
```python
# Start interactive search session
interactive_search()
```

## ðŸ§  LLM Validation Pipeline (Advanced Feature)

### What is LLM Validation?

The **LLM Validation Pipeline** is an advanced feature that adds a second layer of intelligence to the semantic search results. While vector similarity can find semantically related content, it sometimes returns false positives. The LLM validation layer uses **GPT-4o** to analyze whether the found maintenance comments actually describe the same diagnostic issue as your query.

### Two-Stage Search Process

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚â”€â”€â”€â–¶â”‚ Semantic Search â”‚â”€â”€â”€â–¶â”‚ LLM Validation  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ "broken seatbeltâ”‚    â”‚ â€¢ Vector match  â”‚    â”‚ â€¢ Diagnostic    â”‚
â”‚  buckle won't   â”‚    â”‚ â€¢ Similarity    â”‚    â”‚   accuracy      â”‚
â”‚  latch"         â”‚    â”‚   scoring       â”‚    â”‚ â€¢ Relevance     â”‚
â”‚                 â”‚    â”‚ â€¢ Date ranking  â”‚    â”‚   validation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                        â”‚
                                â–¼                        â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Semantic Resultsâ”‚    â”‚ Validated       â”‚
                       â”‚                 â”‚    â”‚ Results         â”‚
                       â”‚ â€¢ 5-10 matches  â”‚    â”‚                 â”‚
                       â”‚ â€¢ Vector scores â”‚    â”‚ â€¢ Filtered      â”‚
                       â”‚ â€¢ All metadata  â”‚    â”‚ â€¢ Explained     â”‚
                       â”‚                 â”‚    â”‚ â€¢ Confident     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What LLM Validation Provides

1. **Diagnostic Accuracy Checking**
   - Validates that maintenance comments describe the same issue as your query
   - Distinguishes between similar-sounding but different problems
   - Example: "seatbelt buckle broken" vs "seatbelt webbing frayed"

2. **Relevance Scoring** (0.0 - 1.0)
   - Provides confidence scores for each result
   - Higher scores indicate better diagnostic matches
   - Helps prioritize the most relevant results

3. **Detailed Explanations**
   - Explains why each result matches or doesn't match
   - Identifies key similarities between query and results
   - Highlights potential concerns or limitations

4. **False Positive Filtering**
   - Removes results that are semantically similar but diagnostically different
   - Improves precision of search results
   - Reduces noise in critical maintenance searches

### LLM Validation Features

#### Input Analysis
- **Query Understanding**: Extracts diagnostic intent from user queries
- **Context Awareness**: Considers automotive maintenance domain knowledge
- **Problem Classification**: Categorizes types of maintenance issues

#### Result Validation
- **Diagnostic Matching**: Compares maintenance comments against query intent
- **Similarity Assessment**: Evaluates relevance beyond vector similarity
- **Confidence Scoring**: Provides numerical confidence levels (0.0-1.0)

#### Output Enhancement
- **Detailed Explanations**: Clear reasoning for each validation decision
- **Key Similarities**: Lists specific matching elements
- **Concern Flagging**: Identifies potential issues with matches
- **Recommendations**: Suggests actions based on validated results

### Configuration Options

#### Environment Variables (.env file)
```bash
# LLM Model for validation
LLM_MODEL=gpt-4o

# Temperature for consistent validation (low = more consistent)
TEMPERATURE=0.1

# OpenAI API Key (required)
OPENAI_API_KEY=your_api_key_here
```

#### Function Parameters
```python
semantic_search_with_llm_validation(
    query="your search query",
    k=5,                          # Initial results to retrieve
    similarity_threshold=0.6,      # Vector similarity threshold
    enable_llm_validation=True,    # Enable/disable LLM validation
    max_validate=3                 # Max results to validate with LLM
)
```

### Usage Examples

#### Basic LLM-Enhanced Search
```python
# Enhanced search with validation
results = semantic_search_with_llm_validation(
    query="seatbelt buckle mechanism is broken",
    enable_llm_validation=True
)

# Display enhanced results
display_validated_results(results)
```

#### Advanced Configuration
```python
# Fine-tuned search with custom parameters
results = semantic_search_with_llm_validation(
    query="vehicle safety equipment malfunction",
    k=8,                          # Get 8 initial semantic matches
    similarity_threshold=0.5,      # Lower threshold for broader search
    enable_llm_validation=True,    # Enable LLM validation
    max_validate=5                 # Validate top 5 results
)
```

#### Performance vs. Accuracy Trade-off
```python
# Fast search (semantic only)
fast_results = semantic_search_with_llm_validation(
    query="broken buckle",
    enable_llm_validation=False    # Skip LLM validation for speed
)

# Accurate search (with LLM validation)
accurate_results = semantic_search_with_llm_validation(
    query="broken buckle",
    enable_llm_validation=True     # Include LLM validation for accuracy
)
```

### Understanding Validation Results

#### Result Structure
```python
{
    "query": "original search query",
    "semantic_results": [...],           # Raw vector search results
    "validation_results": {
        "overall_assessment": "...",     # LLM's general assessment
        "validated_results": [...],      # Individual result validations
        "recommendations": "..."         # Actionable advice
    },
    "final_results": [...],             # Filtered and enhanced results
    "total_semantic_matches": 5,        # Count of semantic matches
    "total_validated_matches": 3        # Count of validated matches
}
```

#### Individual Result Validation
```python
{
    "result_index": 1,
    "relevance_score": 0.85,           # LLM confidence (0.0-1.0)
    "is_diagnostic_match": true,       # Boolean match indicator
    "explanation": "This result describes...",
    "key_similarities": ["buckle", "latch", "safety"],
    "concerns": ["age of repair", "different vehicle type"]
}
```

### Performance Considerations

#### When to Use LLM Validation
- âœ… **Critical maintenance searches** where accuracy is paramount
- âœ… **Complex diagnostic queries** with multiple symptoms
- âœ… **Quality assurance** for important maintenance decisions
- âœ… **Training and analysis** of maintenance patterns

#### When to Skip LLM Validation
- âš¡ **Quick exploratory searches** where speed is preferred
- âš¡ **High-volume automated queries** to minimize API costs
- âš¡ **Simple keyword searches** with obvious semantic matches
- âš¡ **Cost-sensitive applications** with API usage limits

#### Cost and Speed Trade-offs
| Search Type | Speed | Accuracy | API Calls | Best For |
|-------------|-------|----------|-----------|----------|
| Semantic Only | Fast (< 1s) | Good | 1 per search | Exploration |
| LLM Enhanced | Moderate (2-5s) | Excellent | 2+ per search | Critical queries |

### Best Practices

#### Query Formulation
- **Be specific**: "seatbelt buckle won't latch" vs "seatbelt problem"
- **Include symptoms**: "makes clicking noise when pressed"
- **Mention context**: "safety inspection failure" or "urgent repair"

#### Parameter Tuning
- **Start with defaults**: `similarity_threshold=0.6`, `max_validate=3`
- **Adjust based on results**: Lower threshold if too few results
- **Balance cost vs. accuracy**: More validation = better results but higher cost

#### Result Interpretation
- **High LLM scores (0.8+)**: Very confident matches
- **Medium scores (0.6-0.8)**: Good matches worth investigating
- **Low scores (< 0.6)**: May be false positives
- **Check explanations**: Read LLM reasoning for context

### Troubleshooting

#### Common Issues
1. **"LLM validation failed"**
   - Check OpenAI API key and credits
   - Verify internet connection
   - Try with `enable_llm_validation=False` to test semantic search

2. **"No validated results"**
   - LLM may be filtering out false positives
   - Try lowering `similarity_threshold`
   - Review LLM assessment in results

3. **"Slow response times"**
   - Reduce `max_validate` parameter
   - Use `enable_llm_validation=False` for faster searches
   - Consider caching for repeated queries

#### Error Recovery
The system gracefully handles LLM failures:
- Falls back to semantic search results
- Provides error messages in results
- Allows manual retry with different parameters

### Technical Implementation

#### LangChain Integration
```python
# LLM validation chain using LangChain Expression Language (LCEL)
validation_chain = validation_prompt | validation_llm | StrOutputParser()
```

#### Prompt Engineering
The validation prompt includes:
- **Domain expertise**: Automotive maintenance knowledge
- **Clear instructions**: Specific validation criteria
- **Structured output**: JSON format for parsing
- **Example scenarios**: Template for consistent responses

#### Error Handling
- **API timeouts**: Graceful degradation to semantic results
- **JSON parsing errors**: Fallback text parsing
- **Rate limiting**: Automatic retry with exponential backoff

---

### Interactive Search

## ðŸ“ˆ Performance Metrics

- **Database Size**: 237 indexed documents
- **Embedding Model**: OpenAI text-embedding-3-small (1536 dimensions)
- **Search Speed**: Sub-second response times
- **Accuracy**: Similarity scores from 0.0 to 1.0+ (higher = more similar)

## ðŸŽ›ï¸ Customization Options

### Similarity Thresholds
- **0.8+**: Very high similarity (exact matches)
- **0.6-0.8**: Good semantic matches
- **0.4-0.6**: Broader conceptual matches
- **Below 0.4**: May include less relevant results

### Search Parameters
```python
SIMILARITY_THRESHOLD = 0.7  # Default threshold
COLLECTION_NAME = "seatbelt_comments"  # Database collection
PERSIST_DIRECTORY = "./chroma_db"  # Storage location
```

## ðŸ” Understanding the Results

### Result Format
Each search result includes:
- **Similarity Score**: How closely the result matches your query
- **Full Comment**: The complete maintenance comment
- **Metadata**: Date, vehicle ID, status, costs, etc.
- **Ranking**: Sorted by date (newest first), then by similarity

### Interpreting Similarity Scores
- **Semantic Similarity 1.0+**: Exceptional vector match (may indicate duplicates)
- **Semantic Similarity 0.8-1.0**: Very high semantic relevance
- **Semantic Similarity 0.6-0.8**: Good semantic match
- **Semantic Similarity 0.4-0.6**: Moderate relevance
- **Semantic Similarity < 0.4**: Low relevance (consider raising threshold)

**Note**: With LLM validation enabled, semantic scores are supplemented by LLM relevance scores for better accuracy.

## ðŸ› ï¸ Technical Architecture

### Vector Database Structure
```
Document = {
    page_content: "The actual comment text",
    metadata: {
        Date: "2024-01-15",
        VehicleID: "FLEET001",
        Status: "Completed",
        Cost: "$125.50",
        ... (all other Excel columns)
    }
}
```

### LangChain Expression Language (LCEL) Pipeline
1. **Query Embedding**: Convert search query to vector
2. **Similarity Search**: Find similar vectors in database
3. **Threshold Filtering**: Remove results below threshold
4. **Date Ranking**: Sort by date (newest first)
5. **Result Formatting**: Present with metadata

### Enhanced LCEL Pipeline with LLM Validation
1. **Query Embedding**: Convert search query to vector
2. **Similarity Search**: Find similar vectors in database  
3. **Threshold Filtering**: Remove results below threshold
4. **Date Ranking**: Sort by date (newest first)
5. **LLM Validation**: Analyze diagnostic relevance with GPT-4o
6. **Relevance Filtering**: Remove false positives based on LLM assessment
7. **Enhanced Formatting**: Present with LLM explanations and confidence scores

## ðŸŽ¯ Real-World Applications

This approach can be applied to:
- **Customer Support**: Search support tickets by issue description
- **Legal Documents**: Find relevant case precedents
- **Research Papers**: Discover related studies
- **Product Catalogs**: Match products to customer needs
- **Knowledge Bases**: Intelligent FAQ systems

## ðŸš¨ Troubleshooting

### Common Issues

1. **"No results found"**
   - Lower the similarity threshold
   - Try different keywords or phrases
   - Check if the database contains relevant data

2. **"API Key Error"**
   - Verify your OpenAI API key in `.env`
   - Ensure you have sufficient API credits

3. **"Database Connection Error"**
   - Delete the `chroma_db` folder and re-run
   - Check file permissions

4. **"LLM Validation Failed"**
   - Check OpenAI API key and credits in `.env` file
   - Verify internet connection
   - Try with `enable_llm_validation=False` for semantic-only search

5. **"No Validated Results"**
   - LLM may be filtering false positives (this is good!)
   - Try lowering `similarity_threshold` to get more initial results
   - Review LLM assessment message for insights

### Performance Tips
- **Use specific diagnostic queries** for better LLM validation
- **Balance speed vs. accuracy** with `enable_llm_validation` parameter
- **Adjust thresholds** based on your data and use case
- **Monitor API usage** for cost control (LLM validation uses additional API calls)
- **Cache frequent queries** to reduce API costs

## ðŸ“š Learning Resources

- [LangChain Documentation](https://python.langchain.com/)
- [ChromaDB Guide](https://docs.trychroma.com/)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
- [Vector Databases Explained](https://www.pinecone.io/learn/vector-database/)

## ðŸ¤ Contributing

To extend this demo:
1. **Add new data sources** by modifying the data loading section
2. **Implement custom ranking** by adjusting the LCEL pipeline
3. **Create specialized search functions** for specific use cases
4. **Add data visualization** for search analytics
5. **Enhance LLM validation** with domain-specific prompts
6. **Implement result caching** for improved performance
7. **Add batch processing** for multiple queries

## ðŸ“„ License

This demo is provided for educational and demonstration purposes. Please ensure you have appropriate licenses for any data used with this system.

---

*Built with LangChain, ChromaDB, OpenAI embeddings, and GPT-4o validation*

### ðŸ†• Latest Updates

**LLM Validation Pipeline** - Enhanced the semantic search with intelligent validation:
- Added GPT-4o powered diagnostic accuracy checking
- Implemented two-stage search process for higher precision
- Included detailed explanations and confidence scoring
- Added false positive filtering for better results
- Configured environment-based model selection

This creates a **production-ready intelligent search system** that combines the speed of vector search with the diagnostic accuracy of Large Language Model validation!
